{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XebDJ3UnS3n3"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_-HjrL6S3n5"
   },
   "source": [
    "# Lab 5.3.1 \n",
    "# *Support Vector Machines*\n",
    "\n",
    "SVMs use linear algebra to find an (n-1)-dimensional boundary that separates classes within an n-dimensional space. In practical terms, this technique provides a conceptually simple way to predict class membership from a set of features. \n",
    "\n",
    "The standard (linear) SVM is immediately applicable to linear classification problems. Furthermore, by applying transformations to the feature space it is possible to tackle nonlinear classificaiton problems. These transforms are called *kernels*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azVVNUxHYKej"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:13:16.458182Z",
     "start_time": "2019-05-09T05:13:16.454244Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aICmn_7xYKek"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_csv = '../DATA/breast-cancer-wisconsin-data.csv'\n",
    "df = pd.read_csv(breast_cancer_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPRqG96QYKen"
   },
   "source": [
    "### 2. EDA \n",
    "\n",
    "- Explore dataset. Clean data (if required)\n",
    "- Find features to predict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null Values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Unnamed: 32' Features\n",
    "\n",
    "df.drop(columns = 'Unnamed: 32', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Omwx5vVbYKeo"
   },
   "source": [
    "### 3. Logistic Regression Model\n",
    "\n",
    "#### 3.1 Use Logistic Regression\n",
    "\n",
    "Use Logistic Regression and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     B  M\n",
       "0    0  1\n",
       "1    0  1\n",
       "2    0  1\n",
       "3    0  1\n",
       "4    0  1\n",
       "..  .. ..\n",
       "564  0  1\n",
       "565  0  1\n",
       "566  0  1\n",
       "567  0  1\n",
       "568  1  0\n",
       "\n",
       "[569 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one = pd.get_dummies(df.diagnosis)\n",
    "df_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>is_cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302        17.99         10.38          122.80     1001.0   \n",
       "1      842517        20.57         17.77          132.90     1326.0   \n",
       "2    84300903        19.69         21.25          130.00     1203.0   \n",
       "3    84348301        11.42         20.38           77.58      386.1   \n",
       "4    84358402        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564    926424        21.56         22.39          142.00     1479.0   \n",
       "565    926682        20.13         28.25          131.20     1261.0   \n",
       "566    926954        16.60         28.08          108.30      858.1   \n",
       "567    927241        20.60         29.33          140.10     1265.0   \n",
       "568     92751         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0           0.2419  ...          17.33           184.60      2019.0   \n",
       "1           0.1812  ...          23.41           158.80      1956.0   \n",
       "2           0.2069  ...          25.53           152.50      1709.0   \n",
       "3           0.2597  ...          26.50            98.87       567.7   \n",
       "4           0.1809  ...          16.67           152.20      1575.0   \n",
       "..             ...  ...            ...              ...         ...   \n",
       "564         0.1726  ...          26.40           166.10      2027.0   \n",
       "565         0.1752  ...          38.25           155.00      1731.0   \n",
       "566         0.1590  ...          34.12           126.70      1124.0   \n",
       "567         0.2397  ...          39.42           184.60      1821.0   \n",
       "568         0.1587  ...          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  is_cancer  \n",
       "0                  0.2654          0.4601                  0.11890          0  \n",
       "1                  0.1860          0.2750                  0.08902          0  \n",
       "2                  0.2430          0.3613                  0.08758          0  \n",
       "3                  0.2575          0.6638                  0.17300          0  \n",
       "4                  0.1625          0.2364                  0.07678          0  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115          0  \n",
       "565                0.1628          0.2572                  0.06637          0  \n",
       "566                0.1418          0.2218                  0.07820          0  \n",
       "567                0.2650          0.4087                  0.12400          0  \n",
       "568                0.0000          0.2871                  0.07039          1  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = ['diagnosis', 'M']\n",
    "rename_columns = {\n",
    "    'B' : 'is_cancer'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat((df, df_one), axis = 1)\n",
    "df = df.drop(columns = drop_columns, axis = 1)\n",
    "df = df.rename(columns = rename_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['id', 'is_cancer'])\n",
    "y = df['is_cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, stratify = y , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression(max_iter = 2000)\n",
    "\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy  0.9582417582417583\n"
     ]
    }
   ],
   "source": [
    "# Train Accuracy score\n",
    "train_accuracy = log.score(X_train, y_train)\n",
    "print('Train Accuracy ', train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "#Test Accuracy score\n",
    "test_accuracy = log.score(X_test, y_test)\n",
    "print('Test Accuracy ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= log.predict(X_test)\n",
    "\n",
    "# predict test probability:\n",
    "prob_preds = log.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values \n",
      " 70 2 2 40\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp, tn = confusion_matrix(y_test, y_pred, labels = [1,0]).reshape(-1)\n",
    "print('Outcome values \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9494505494505494"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(log, X_train, y_train, cv = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391304347826086"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(log, X_test, y_test, cv = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        42\n",
      "           1       0.97      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_cancer</th>\n",
       "      <th>predicted_healthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_cancer</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_healthy</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_cancer  predicted_healthy\n",
       "is_cancer                 40                  2\n",
       "is_healthy                 2                 70"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm_index = ['is_cancer', 'is_healthy']\n",
    "cm_columns = ['predicted_cancer', 'predicted_healthy']\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "cm = pd.DataFrame(cm, index = cm_index, columns = cm_columns)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / float(tp + tn + fp + fn)\n",
    "print('Classification accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error is  0.03508771929824561\n"
     ]
    }
   ],
   "source": [
    "classification_error = (fp + fn)/ float(tp + tn + fp + fn)\n",
    "print('Classification error is ', classification_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr is  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "tpr = tp / float(fn + tp)\n",
    "print('tpr is ', tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Receiver operating characteristc (ROC) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mogg_w8vYKep"
   },
   "source": [
    "### 4. Support Vector Machine\n",
    "\n",
    "#### 4.1 Use Support Vector Machine\n",
    "\n",
    "Use Support Vector Machine and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['id', 'is_cancer'])\n",
    "y = df['is_cancer']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, stratify = y , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel = 'linear', probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score  0.9582417582417583\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)\n",
    "train_accuracy_score = svc.score(X_train, y_train)\n",
    "print('Train Accuracy Score ', train_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score  0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_score = svc.score(X_test, y_test)\n",
    "print('Test Accuracy Score ', test_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test class\n",
    "y_pred= svc.predict(X_test)\n",
    "\n",
    "# predict test probability:\n",
    "preds = svc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values \n",
      " 71 1 4 38\n"
     ]
    }
   ],
   "source": [
    "svc_tp, svc_fn, svc_fp, svc_tn = confusion_matrix(y_test, y_pred, labels = [1,0]).reshape(-1)\n",
    "print('Outcome values \\n', svc_tp, svc_fn, svc_fp, svc_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_cancer</th>\n",
       "      <th>predicted_healthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_cancer</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_healthy</th>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_cancer  predicted_healthy\n",
       "is_cancer                 38                  1\n",
       "is_healthy                 4                 71"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_index = ['is_cancer', 'is_healthy']\n",
    "cm_columns = ['predicted_cancer', 'predicted_healthy']\n",
    "svc_cm = confusion_matrix(y_pred, y_test)\n",
    "svc_cm = pd.DataFrame(svc_cm, index = cm_index, columns = cm_columns)\n",
    "svc_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        42\n",
      "           1       0.95      0.99      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdzQkTb7YKeq"
   },
   "source": [
    "### 5. Naive Bayes\n",
    "#### 5.1 Use Naive Bayes\n",
    "\n",
    "Use Naive Bayes and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['id', 'is_cancer'])\n",
    "y = df['is_cancer']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, stratify = y , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  0.9406593406593406\n"
     ]
    }
   ],
   "source": [
    "gaussianNB.fit(X_train, y_train)\n",
    "train_accuracy = gaussianNB.score(X_train, y_train)\n",
    "print('Train accuracy ', train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "gaussianNB.fit(X_test, y_test)\n",
    "test_accuracy = gaussianNB.score(X_test, y_test)\n",
    "print('Test accuracy ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test class\n",
    "y_pred= gaussianNB.predict(X_test)\n",
    "\n",
    "# predict test probability:\n",
    "preds = gaussianNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values \n",
      " 72 0 4 38\n"
     ]
    }
   ],
   "source": [
    "gaussian_tp, gaussian_fn, gaussian_fp, gaussian_tn = confusion_matrix(y_test, y_pred, labels = [1,0]).reshape(-1)\n",
    "print('Outcome values \\n', gaussian_tp, gaussian_fn, gaussian_fp, gaussian_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_cancer</th>\n",
       "      <th>predicted_healthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_cancer</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_healthy</th>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_cancer  predicted_healthy\n",
       "is_cancer                 38                  0\n",
       "is_healthy                 4                 72"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_index = ['is_cancer', 'is_healthy']\n",
    "cm_columns = ['predicted_cancer', 'predicted_healthy']\n",
    "gaussianNB_cm = confusion_matrix(y_pred, y_test)\n",
    "gaussianNB_cm = pd.DataFrame(gaussianNB_cm, index = cm_index, columns = cm_columns)\n",
    "gaussianNB_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        42\n",
      "           1       0.95      1.00      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.95      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoGxthaeYKer"
   },
   "source": [
    "### 6 Gridsearch optimal parameters for all three models.\n",
    "\n",
    "Is there any difference between accuracy score of Logistic Regression and SVM? Use grid serach to find optimal parameter for both these models.\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
    "\n",
    "> It is possible and recommended to search the hyper-parameter space for the best cross validation score.\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "**Note:** It'll take time to execute this. After running the cell, wait for result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeqrbsyNYKes"
   },
   "source": [
    "#### 6.1 Find Best Estimator For Logistic Regression \n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:29.397881Z",
     "start_time": "2019-05-09T05:40:29.392602Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UkQ9RBQZYKet"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.94727527        nan 0.93496351        nan 0.94204316]\n",
      "  warnings.warn(\n",
      "C:\\Users\\darry\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 10, 100], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': [1, 10, 100]\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(estimator = LogisticRegression(),\n",
    "            param_grid = lr_params)\n",
    "\n",
    "lr_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for Logistic Regression 0.9472752678155567\n",
      "Best Estimator for Logistic Regression 1\n"
     ]
    }
   ],
   "source": [
    "print('Best Score for Logistic Regression', lr_grid.best_score_)\n",
    "print('Best Estimator for Logistic Regression', lr_grid.best_estimator_.C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:14.036840Z",
     "start_time": "2019-05-09T05:23:14.032847Z"
    },
    "colab_type": "text",
    "id": "ioLgY3bxYKev"
   },
   "source": [
    "#### 6.2 Find Best Estimator For SVM\n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:31.617090Z",
     "start_time": "2019-05-09T05:40:31.612996Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vgi61VpWYKew"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear', probability=True),\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.001, 0.0001],\n",
       "                         'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_params = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.001, 0.0001],\n",
    "    'kernel': ['linear','rbf']\n",
    "}\n",
    "\n",
    "svc_grid = GridSearchCV(estimator = svc, \n",
    "                        param_grid = svc_params)\n",
    "svc_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC best score is  0.9631268436578171\n",
      "SVC best estimator is  100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('SVC best score is ',svc_grid.best_score_)\n",
    "print('SVC best estimator is ', svc_grid.best_estimator_.C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:59.157703Z",
     "start_time": "2019-05-09T05:23:59.153713Z"
    },
    "colab_type": "text",
    "id": "HrS04DfuYKez"
   },
   "source": [
    "#### 6.3 Plot the ROC curve for the SVM, Logistic Regressions and Naive Bayes on the same plot\n",
    "\n",
    "Find out which model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:28:56.671590Z",
     "start_time": "2019-05-09T05:28:56.421258Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "q9TBM2axYKe0",
    "outputId": "8f525757-6f7f-4a8b-d154-235ae82cfdf6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAASICAYAAAC9Xm5SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAB3kklEQVR4nOzdeZhkZXn/4e/DDCIIyCpRUEHZd3QQcQOUzSggogZBWYxRVNTgTyNxC4pRcEkQRQkmBMSFaJRFQUFNCHFlURSQsKgoi8qgrLIJvL8/qmZsmp6lZ/qdppv7vq6+eurU6VNP1dSo/fGct6q1FgAAAADoYanJHgAAAACA6Ut8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAeoqrqgKpqVbX9ZM/CA1XV1VV1zmTPMV5Tde7JUlVrD/8NHjbBxz2hqtpEHhMAHsrEJwAeNqpq++EvkiO/bq+qH1XVIVU1c7JnnIqqasWqevfwdbytqu6oqp9V1Yerao3Jnm9RVdVhVfWiyZ5jQapquar626r636r6Q1X9qap+V1VnDgPmtHxfD5/zAZM9x7wMX/u/fQjMcc7wP+v+VFV/MY99PjbiPxO3X7ITAvBwUK35P10AeHgY/lL130m+kOTMJJXkL5Lsl2TTJJ9urb1msuYbrapmJFk6yT2ttfsne56xVNX6Sc5K8sQkX8ng9f1TkqcneUWSW5Ps1lr7/qQNuYiGZ6ac2Fo7YIz7lknSWmv3LPHBHjjHuknOSLJ+km8lOTvJjUkek2TH4deHW2t/N9z/6iRXt9a2n4x5J9KSeC5VVUmWSXJva+3ecf7sOUnWbq2tPcZ9SyeZ0Vq7ayLmXIg5njm8+Y7W2odH3f+IJNcneVSSRybZobV2Tu+5AHh4mZb/TxgALMCPWmufnXOjqj6Z5P+SvLqq3tlamz15o/1Za+2+JPdN1uNX1bJJ/jSvX7qrarkkX02yZgaB6YwRdx83fF2/leS0qtqstfa77kOPPed8n8eiaK3dPVHHWlTD5/W1JE9Ksldr7SujdjmyqrZOsvUSHy5z4+kyrbU7JuPxF0dVrdBau60N/l/aCQ9ErbU/ZRBpl5S7k/xXkgOTfHjUfXskWTXJ55PsswRnAuBhxGV3ADzstdb+mOQHGZwJ9eSR91XVY6vqU1X166q6p6qur6rjquoxo48zvPzsH6vqsqq6q6p+X1Xfqaq9F+WYo9d8qqrnD2+/aaznUVXfr6rZw7Mq5mxbr6pOqqrfDB/r6uHlcI8a9bMnDI+9elUdX1W/S/LHJGvN56X76wzOuPnnUeFpzut6QZJ3JFk9ydtGPNacyx8PqKo3VtUVw9friqp64zye24Q8j6p6fVWdXVXXDY/zm6r6bFWtPeIYa9ef1+PZf8TlSG3EPg9aO2nOtqrasKrOqMEliLdU1X+OdblTVW0+nOWPw/fKiVW12vCxTpjP6z7Hq5NskOSjY4SnJElr7fzW2ifHeOwFzlhVj6uqj1bVRVV10/Dv6GdV9fZhWBq575z36o41uATz5xlEm5cN79+5qv6jqn5RVXdW1c3D577dWHNX1bpV9e9Vde2IfyOnVdVTh/e3DM62264eeBnt2iOOMauqTqmqG6vq7qq6vKreWaMuQxz+nV1dVU8avg5/yOCMvXmu+VRV+1XVecPn8cfh8/pcVa0+vP/qJNsleeKo+bYf3j/mmk9V9RdVdfTweHdX1Q1V9c2q2mnEPssN//4eO9ZrNx//nmSjqtpm1PYDk/wkyY/HeTwAWGjOfAKAgTnR6Q9zNlTVE5J8P8kjkvxbkp8nWTfJ65LsUFWzWmu3DPddKcl3kmyS5D+TfCrJjCRbJXlhkpPHe8wxnJ3kNxlcJnj0yDuqar0MLnU7enhWRYa/qP9XkpuT/EuS65JskeRNSZ5ZVdvN2XeEbyb5bZLDM7gM5/b5vGYvGX7/9Hz2OSHJUUn2SvLWUfe9MYPLHv8lyW1JXp7k6KpapbX23hHPbSKfx1szCI1HZ/B3vWkGEee5NTg76/dJZid5ZZKTkvxvkuPm8/xGWzPJOUlOySC4bZHktUlWTLLziOe03vDYSw1nuS7JXyb5+jgea87rP575FnrGJJsnefFwv59ncAno85MckcHZVq8d49gfGe736QwCzuXD7QckWSXJZ5JcO5zh1Um+XVU7tNb+d84BqmpWkm8Pj/NvSS4Z/ux2SZ6R5MIM/n7+OYNLDP9xxOPPHh7jL4dzX5Xkoxn8XW+b5H1Jtkzy0lFzL5/kf5J8N8k7M7hscUxV9YokJ2bw9/eeJHcmecLwtXnMcIa/TfLBJKslOWTEj182n+OuPXz8NTJ4nS7I4L379Awun/zmcNenZXB564kZvK4L62tJbkjyqiQ/HD7m4zL4O39LBv+ZBAB9tNZ8+fLly5evh8VXku2TtAx+YVwtgzNyNktyzHD7eaP2Py2DX9bWGrV9VpJ7kxw2Ytsnh8d4zRiPu9QiHvOA4TG3H7Htw8NtG4/6+cOH258yYttPMriccIVR++453PeAEdtOGG777Dhez98nuXUh9rt4eOzlR/093Dbydcjgl9/zMrgcaa0ezyPJo8bY9rzhz/zdqO0tyQnzOM7VSc4ZY1tL8rJR2+e8vzYcse2Lw23PHLXvf8zvcRfl9V+MGZfNcH3QUfuelMHloI8d4716eZLlFvJ1XyODeHTmiG2VQWy6K8nmC/i39KC/g+H2R2YQHs9NMnPUfYfkwf+mzhlue/8Yx1p7eN/If5dfySCszRy9/6ifPSeDNanGuu+EDNYMG7ntzOFj7bKA5739wr5HRsxx+/DPH01yS5Jlh7ffkcEleatmEGYf8Nr48uXLly9fE/XlsjsAHo7em8HZCTck+WmS12fwC+Xuc3aoqkdncMbS6UnuGl4OtVpVrZbBL71XZXiWSFUtlWTvDM5qeNBZQG24WPh4jjkfJw6/7zdi1spgce9LWms/Gm7bLIMzVz6fZJlRj/WdDC5FG+uxPrKAxx9pxQx+kV2QOfs8etT2z7XWrp1zow0W7/7nDM7M3q3H82iDSyxTVUtV1aOHx/nJcMbRlyMtiutba18cte2/ht/XHT72jAzOcjqvtfbdUft+dByPtWKGl4dN9IxJ0lq7s7U2KEJVj6iqVYav11kZnLE1a4xjf6qNscbTnNd9eKzlq2rVDALWD/PA133LDM4e/PfW2k/HOM7CLLy/UwZh69+TrDTqPXPmcJ/Fee/fkmS5JC8Y/ttbbFW1SpJdk3yjtXbW6PtHPu/W2jmttWpjLIS/EI7P4H3z4uHtA5Kc1gZn/AFANy67A+Dh6LgkX8rgsp7Nkrw9gzWBRi4svEEGv2D/9fBrLL8Yfl8tycoZ/OI4v4+RHc8xx9Rau6Sqfpxk36p6x/CX0udkcIbG20bsutHw+3uHX2NZY4xtV8zv8Ue5NYNfZBdkzj6jQ9VYlyD9bPj9ScPvE/o8quq5GZz5tk0GZ8iMtPI8jj8eY/39zfnFftXh99UzuJzq8jH2HWvbvNyaZIVx7D/HwsyY4dpIh2YQOtfN4KykkcZ6veb1uj85g8vjdkmy0qi7R/6bWW/4fXHWH5rznjl+PvuMfs/Mbq3dvJDH/0AG/+ZOTfL7qvqfDC6X/I/W2m3jmHOkOa9v13WXWmuXVtX5SQ6sql9n8Hq/uedjAkAiPgHw8HRla+1bwz9/vaq+k8FZNMdmcAZT8udftD+bP59tNNqdo/adX3ga7zHn58QM1lF6bgafJrdfBmeRfG6Mx/pokm/M4zg3jd4w1lkr83FJkudU1bqttavG2qEGn4i3QQaXH41eP2qs12t04Jiw51GDT347O4MzzA5N8ssMXu+WwZpcE3FG+Pw+nbBGfR/Lgt5DI815/Z/UWptvtBxlYWZMkn/KYF2u/8ggHN2QwSWRT0lyZMZ+vcZ63ZfP4BK4R2Xwvr04g0su70/y9xm8j0c//nheh3k9h7cluWge+1w/6vZCv+9ba1dW1cYZXK75vAzWovp0kvdW1XNaaz8f37hJJuZ5L6zjM7hMOBmsNXb2EnhMAB7mxCcAHvZaa9+rqpOS7FdVR7fWvpdBoGhJHjEiVM3L7AwCyJYL2G88x5yfz2ew9tN+VfXdDBae/mZr7Tcj9rly+P2+xXys+flKBmeAvDqDmDOW/TJYy2msT2PbeIxtc85amRNTJvJ57JPBIvDPb639cs7GGnxi3kSc9bSwbsjgcsENxrhvw3Ec58v58+v/jgmYa7RXJjm3tTb60xrXncf+8/K8JI9L8qrW2r+POtb7R+0758yvrRbiuPMKNXPeM3/s9d5vrd2dwSV8ZyZzFzg/I4OFu9+wgPnGcuVw/4V53ovrCxmExecl+UBrbX4xEgAmhDWfAGDg8AzOCHlfkgzXQDkzyYur6umjd66B1Yf73p/BL3QbV9WDLqebsy7MeI45P6212Rlc5vPiJPtmcFnb6DOpfpzBmTEHVdWTRt2Xqpo5XGdmcfxrBkHtkKradYzHeEoGn/g1O4NYNtq+VbXWiP0fkcGC0Pdl8MlcE/085vySPfrMo3dk7P9NdHsGn7I2oYa/7H89ydOq6pmj7v5/4zjUv2YQa95aVXuMtUNVPbWqXr9ok+a+jHqthqHukLF3n+9xMsaxds6D19n6SZJLk7yqqjYZfaBRayzN6+/nrAwC36FjvTeqatmqWpTLFef8/GpjbP7R8PvIx7s9ycoLsy5Ua+0PGbwnnl9VO47xmDXiz8tV1YZV9djxTT73sW5JclAGl7H+y6IcAwDGy5lPAJCktXZVVZ2cQRB5dht89PvrMrgc79yq+kwGIWSpDNYj2iODj0M/bHiId2Vw+dC/Dn+p/k4Gv2xvlcF/375yuN94jjk/J2awQPqcT686bdTzaVX1ygwWkv5pVR2fwS/1y2WwvsyLM7jk6YSFeoHG0Fr7Y1XtnsHlcGdU1Zcz+GStezP4OPhXZvAL+Itaa78d4xBXJPlhVR2bwWVY+yTZOsnhrbVrOjyPUzIIJ2dW1XFJ7slgcerNM/jUtdF+kGTHqnp7kl8Pxzl5IR5nYbwrg/WPvlFVn0hybZIXZLAeVLIQZ8201u6oqhdmcMbNqVV1dpJvZrB+0+pJdhg+xocWccb/TPLaqvqPDC7vXCPJq/Ln9aEW1ncy+PS5j1bV2hk81y0zeH9cnMG6a3OeU6uqA5N8O8l5VfVvGcTHlTK4vO0bST4+3P0HSf66qg7PYP2w+5N8dfi+3C+DNZkuH75nrhoeY8MM3jN7ZvBeXRRnV9UtGVxKeM3wuAdk8Hd20oj9fpDBBwx8oqq+l0GE+6/W2g3zOO7BSb6XwaXAJya5MINPHNwmgw8kePtwv6cl+e8M/jPggEV5Aq21zyzKzwHAohKfAODP/jHJyzM4+2mH1to1VfXUDH7p2yODT5S7K4NfOL+aZO4nhrXWbqqqbTM4i2bOL7e3ZbCA9sdH7LfQx1yAryX5QwZnWvxra+1Ba0W11i6qqq0yiDO7Z3C2w20Z/CJ7Qga/4C+W1tplVbV5BosWvziDT3GbkeRXGTzvj8wjPGV4/4oZrCv0hAwCz9+21j7W43m01r5bVXsleXcGZ7rdmUFU2S6DkDDa65Mck+Sd+fPC3hMSn1prl1fVczL4hLU3Z/Ae+FoGl2z9Igu39tecaLpVktcm2Ws46/IZvDcuSLJ/BpdpLoq3ZPA6vyyD9+o1GSzWf34Gr9tCaa3dXFVzItgbM/jfnxdm8F7564yIT8P9zx+uz/Xu4WMflEEcPC/JyE8HfGcG7/83ZBCAKsk6GVxud9bwGIdm8G9s9Qwujf15BpecPeiT9MbhU8O5Xjt8/N9nEJHf2Fr77xH7HZVBVH7J8DkslUEQHDM+tdZ+WVWzhs/7LzO4ZPWmDM4GO24x5gWASVfz/1AeAICJVVXbZ3DmxoGttRMmdZiHmGGYvCDJ37fWjpjseQAAJoI1nwAAJkFVLTvqdiX5u+HNby75iQAA+nDZHQDA5Lioqv4rg3WPHpVktyTPTvIfrbULJ3UyAIAJJD4BAEyO0zIITq/M4H+T/TKD9X6OnMyhAAAmmjWfAAAAAOjGmk8AAAAAdDPtLrtbbbXV2tprrz3ZYwAAAABMGxdeeOGNrbXVF+Vnp118WnvttXPBBRdM9hgAAAAA00ZV/WpRf9ZldwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdTFp8qqrjq+qGqrpkHvdXVR1dVVdV1U+r6ilLekYAAAAAFs/MSXzsE5J8Isln5nH/85OsN/zaJsmnht9hUh13/tdzzE+PzP0zfz/ZowAAAMBD3qSd+dRaOzfJH+azyx5JPtMGfpBkpap67JKZDuZNeAIAAICF91Be82nNJNeMuH3tcNuDVNVrquqCqrpg9uzZS2Q4Hr6EJwAAAFh4D+X4VGNsa2Pt2Fo7rrU2q7U2a/XVV+88FgAAAAALazLXfFqQa5M8fsTttZJcP0mzwDxdvP/FE3/Qwx496vYtE/8YAAAAsJDqgLHOEVo4D+Uzn05Pst/wU++enuSW1tpvJnsoAAAAABbepJ35VFVfSLJ9ktWq6tok/5Bk6SRprR2b5Mwkf5nkqiR3JDlwciYFAAAAYFFNWnxqrb18Afe3JG9YQuMAAAAA0MFD+bI7AAAAAKY48QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuZk72ADxM/Py/kq/+bXLzryZ7ksW3zhMeePuwR0/OHAAAADAFOPOJJWO6hCcAAABgXMQnlgzhadGt9MTJngAAAAAWmfgED2UrPTHZ7ajJngIAAAAWmTWfmByH3TLhh1z70DMecPvqI14w4Y+RJDlxswfe7vBcAAAAYLpw5hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABANzMnewAentY+9IzJHgEAAABYApz5BAAAAEA34hPT0uNXWXayRwAAAAAiPjENPX6VZfOBPTeb7DEAAACAWPOJSXL1ES+Y7BEAAACAJcCZTwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABANzMnewDm4+f/lXz1b5ObfzXZk0wJ37v+e3nf99+X626/brJHAQAAAIac+fRQJjyNi/AEAAAADz3i00PZNA1P19caXY47GeFpzeXXXOKPCQAAAFOJ+MQSdX2tkd/vcORkjzEh1lx+zbxn2/dM9hgAAADwkGbNp6nksFu6HHbtQ894wO2rj3hBl8dJkscNv5aEi/e/eAk9EgAAADAvznwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbmZO9gAsvLUPPWOyRwAAAAAYF2c+AQAAANCN+MQDPH6VZSd7BAAAAGAaEZ+Y6/GrLJsP7LnZZI8BAAAATCPWfJpCrj7iBZM9AgAAAMC4OPMJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhm5mQPwMPD967/Xt73/fflutuvm+xRAAAAgCXImU8sEcITAAAAPDyJTywRSzo8rbn8mkv08QAAAICxiU9MO2suv2bes+17JnsMAAAAINZ8YpJcvP/Fkz0CAAAAsAQ48wkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6mTnZAzBv33vkI/O+1VbJdUsP/5pO3GxyBwIAAAAYJ2c+PYQ9IDwBAAAATEHi00PYdA1Pay6/5mSPAAAAACwh4hNL1JrLr5n3bPueyR4DAAAAWEKm56k109TF+1882SMAAAAAjIsznwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgm0mNT1W1a1VdXlVXVdWhY9z/6Kr6alX9pKouraoDJ2NOAAAAABbNpMWnqpqR5Jgkz0+ycZKXV9XGo3Z7Q5Kftda2SLJ9ko9W1SOW6KAAAAAALLLJPPPpaUmuaq39orV2T5KTk+wxap+WZIWqqiTLJ/lDknuX7JgAAAAALKrJjE9rJrlmxO1rh9tG+kSSjZJcn+TiJG9urd2/ZMYDAAAAYHFNZnyqMba1Ubd3SXJRkscl2TLJJ6pqxQcdqOo1VXVBVV0we/bsiZ4TAAAAgEU0mfHp2iSPH3F7rQzOcBrpwCRfaQNXJfllkg1HH6i1dlxrbVZrbdbqq6/ebWAAAAAAxmcy49P5SdarqnWGi4jvneT0Ufv8OsnzkqSq1kiyQZJfLNEpAQAAAFhkMyfrgVtr91bVwUnOSjIjyfGttUur6qDh/ccmOTzJCVV1cQaX6b29tXbjZM0MAAAAwPhMWnxKktbamUnOHLXt2BF/vj7Jzkt6LgAAAAAmxmRedgcAAADANCc+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQzqfGpqnatqsur6qqqOnQe+2xfVRdV1aVV9T9LekYAAAAAFt3MyXrgqpqR5JgkOyW5Nsn5VXV6a+1nI/ZZKcknk+zaWvt1VT1mUoYFAAAAYJFM5plPT0tyVWvtF621e5KcnGSPUfvsk+QrrbVfJ0lr7YYlPCMAAAAAi2Ey49OaSa4Zcfva4baR1k+yclWdU1UXVtV+Yx2oql5TVRdU1QWzZ8/uNC4AAAAA4zWZ8anG2NZG3Z6Z5KlJXpBklyTvrqr1H/RDrR3XWpvVWpu1+uqrT/ykAAAAACySSVvzKYMznR4/4vZaSa4fY58bW2t/TPLHqjo3yRZJrlgyIwIAAACwOCbzzKfzk6xXVetU1SOS7J3k9FH7nJbk2VU1s6qWS7JNksuW8JwAAAAALKJJO/OptXZvVR2c5KwkM5Ic31q7tKoOGt5/bGvtsqr6RpKfJrk/yb+21i6ZrJkBAAAAGJ/JvOwurbUzk5w5atuxo25/OMmHl+RcAAAAAEyMybzsDgAAAIBpTnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxhWfqurxVXV8VV1bVfdU1XOH21cfbt+6z5gAAAAATEULHZ+qap0kFyTZK8mlSWbMua+1NjvJrCSvnugBAQAAAJi6Zo5j339Mcn+STZPcmeSGUfefmWS3CZoLAAAAgGlgPJfd7Zjkk621a5K0Me7/VZK1JmQqAAAAAKaF8cSnFZP8Zj73PyLjO5MKAAAAgGluPPHpmiSbzOf+pye5avHGAQAAAGA6GU98+kqSV1XVpiO2tSSpqr2SvDTJFydwNgAAAACmuPHEp39Mcm2SHyb5bAbh6dCq+n4G0eknST464RMCAAAAMGUtdHxqrd2aZNsk/5pkVpJKslOSDZJ8MskOrbW7egwJAAAAwNQ0rgXChwHqzUneXFWrZxCgZrfWxvr0OwAAAAAe5hb6zKeqes/I9Z5aa7NbazfMCU9VtUlVvafHkAAAAABMTeNZ8+mwJJvP5/5Nk/zDYk0DAAAAwLQynvi0II9Mcu8EHg8AAACAKW6+az5V1YpJVhqxadWqesIYu66SZN8k10zcaAAAAABMdQtacPyQJHPWcWpJjhp+jaWS/N2ETAUAAADAtLCg+HTO8HtlEKFOSfLTUfu0JLcn+UFr7XsTOh0AAAAAU9p841Nr7X+S/E+SVNUTkxzbWvvhkhgMAAAAgKlvQWc+zdVaO7DnIAAAAABMPwsdn+aoqhlJNkyycsb4tLzW2rkTMBcAAAAA08C44lNVvT3JoUlWnM9uMxZrIgAAAACmjQeduTQvVfXqJB9MclGSd2WwCPlRST6c5A9JLkjyqgmfEAAAAIApa6HjU5KDMvhEux2SHDfcdkZr7dAkmydZO856AgAAAGCE8cSnjZJ8afjnNvw+M0laa7/JIEi9eeJGAwAAAGCqG098ui/JH4d/nvN9lRH3X51kvQmYCQAAAIBpYjzx6ddJ1kmS1trdSa5J8uwR92+dwdpPAAAAAJBkfJ92d26SFyT5++HtLyX526paNoOI9Yokx0/seAAAAABMZeOJTx9L8pOqWra1dmeSf0iyfpL9h/efneTQCZ4PAAAAgClsoeNTa+3yJJePuP3HJLtX1aOT3Ndau73DfAAAAABMYeNZ82lMrbVbWmu318ArJ2IoAAAAAKaHxY5Pw+i0T5LLkpyw2BMBAAAAMG0sMD5V1bOr6rSq+llVfaeqXjvivl2SXJLkpCSPTXJkv1EBAAAAmGrmu+ZTVT0zybeSLD1i87ZV9agkj0zy/iQ3Jzk8yVGttZv7jAkAAADAVLSgBcffnuTuJC9J8u0k6yb5TJJ3JVkhyb8k+XvRCQAAAICxLOiyu22S/Etr7auttTtaaz9N8tYkKyX5bGvtdcITAAAAAPOyoPi0apJLR22bc/u0iR8HAAAAgOlkQfFpqST3jNo25/atEz8OAAAAANPJgtZ8SpJHVdUqI27P+fMKo7YnSVprf5iQyQAAAACY8hYmPh07/BrtK2Nsawt5TAAAAAAeBhYUik5cIlMAAAAAMC3NNz611g5cUoMAAAAAMP0saMFxAAAAAFhk4hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdDOu+FRVK1TVe6rqO1V1ZVVtO9y+2nD7hn3GBAAAAGAqmrmwO1bV6km+k+RJSa4afl82SVprN1bV/klWSvKWiR8TAAAAgKlooeNTkvcn+Ysk2yT5dZIbRt1/WpLnTdBcAAAAAEwD47ns7oVJPtla+1GSNsb9v0jy+AmZCgAAAIBpYTzxabUMLrebl/uTPHLxxgEAAABgOhlPfPptkifP5/6tMrgcDwAAAACSjC8+nZnkr6vqsaPvqKptkuyXwbpPAAAAAJBkfPHpvUnuTfLjJB/MYN2n/avqC0nOTXJ9kiMnfEIAAAAApqyFjk+ttd8meXqSHyZ5VZJK8sokL0tydpJnt9b+0GNIAAAAAKammePZubV2TZI9qmrFJBtkEKCuEp0AAAAAGMtCx6eqWrW19vskaa3dmuT8blMBAAAAMC2MZ82n66vqK1W1R1WN64wpAAAAAB6exhOfvpJkl+H331TVx6pqVp+xAAAAAJgOxrPg+MuT/EWS1yT5WZKDk/ywqi6tqrdV1eM6zQgAAADAFDWeM5/SWruttfZvrbXtkjwpyWFJlk5yZJJfVdU3Jn5EAAAAAKaqccWnkVprv2qtHd5aWz/Jvkn+mGSnCZsMAAAAgClvkRcOr6oVkrw0yX5JnpVByLpkguYCAAAAYBoYV3yqqspg0fH9kuyRZNkks5N8IsmJrbUfT/iEAAAAAExZCx2fquojSfZJskaSPyU5I8mJSc5srd3bZzwAAAAAprLxnPn0liTnJ3l/ki+01m7qMxIAAAAA08V44tPGrbX/6zYJAAAAANPOQn/anfAEAAAAwHjN88ynqtpv+MeTWmttxO35aq19ZkImAwAAAGDKm99ldyckaUlOTnLPiNs1n59pScQnAAAAAJLMPz7tkCSttXtG3gYAAACAhTXP+NRa+5/53QYAAACABVnoBcer6viq2mY+9z+tqo6fmLEAAAAAmA4WOj4lOSDJk+dz/zpJ9l+saQAAAACYVsYTnxbkUUn+NIHHAwAAAGCKm9+C46mqJyRZe8SmDavqOWPsukqS1yW5auJGAwAAAGCqm298SnJgkn9I0oZf7xx+jVZJ7h/uDwAAAABJFhyfTk1ydQZx6fgkxyX5/qh9WpLbk5zfWrtmgucDAAAAYAqbb3xqrf0kyU+SpKqemOTLrbVLlsRgAAAAAEx9Czrzaa7W2nt7DgIAAADA9DPP+DRnYfHW2rkjby/InP0BAAAAYH5nPp2TpFXVsq21e+bcns/+Nbx/xoRNBwAAAMCUNr/49KoMYtKfhrd9kh0AAAAA4zLP+NRaO2HU7RO7TwMAAADAtLLUZA8AAAAAwPS10PGpqp5WVX8zatseVXVxVV1XVR+Y+PEAAAAAmMrGc+bTPyTZfc6NqnpCki8k+YsktyR5e1VZFwoAAACAucYTn7ZI8t0Rt/fO4BPutmytbZzk7CSvmcDZAAAAAJjixhOfVk3y2xG3d0lybmvtuuHt05OsN1GDAQAAADD1jSc+3ZxkjSSpqmWSPD3JuSPub0mWnbDJAAAAAJjyZo5j34uSvLqqvpVkzySPTHLWiPvXSfK7iRsNAAAAgKluPPHp8AzWdTovg7Wevtlau2DE/S9M8sMJnA0AAACAKW6h41Nr7XtV9ZQM1nq6JcnJc+6rqlUzCFOnTPiEAAAAAExZ4znzKa21K5JcMcb23yc5ZKKGAgAAAGB6GFd8SpKqWjHJjkmeNNz0iwwuwbttIgcDAAAAYOobV3yqqlcn+WiS5TNY9ykZfMrd7VX1ltbav03wfAAAAABMYQsdn6pq9yTHZXCm03uSXDK8a5Mkb0xyXFXd0Fr76oRPCQAAAMCUNJ4zn/4uyWVJtmmt3T5i+7er6t+T/CDJ25OITwAAAAAkSZYax75bJDlhVHhKkgzXezpxuA8AAAAAJBlffEr+vM7TWNriDAIAAADA9DOe+PSTJPtX1aNG31FVyyc5YLgPAAAAACQZ35pPH0nylSQ/qqqjk/xsuH3OguPrJnnxxI4HAAAAwFS20PGptXZqVR2c5MgkH8+fL7OrJH9McnBr7bSJHxEAAACAqWo8Zz6ltfbJqvp8kp2SrJNBePp5km+21m7pMB8AAAAAU9gC41NVzUyyRwaX1d2Y5LTW2pd6DwYAAADA1Dff+FRVKyc5J8mmGZzl1JJ8qKp2bq1d2H88AAAAAKayBX3a3buSbJbkjAwWFf9EkuWTHNd5LgAAAACmgQVddrdbkm+01nafs6Gqrk7ykapaq7V2bc/hAAAAAJjaFnTm0+OTnDlq21czuATviV0mAgAAAGDaWFB8WibJH0Ztu2nEfQAAAAAwTwuKT/PTJmwKAAAAAKalBa35lCT/r6r2HnF76QzC0z9W1Y2j9m2ttT0mbDoAAAAAprSFiU9bDb9Ge/oY25wNBQAAAMBc841PrbXFuSwPAAAAgIc5cQkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhm5nh/oKrWSfK8JGsk+Vxr7eqqekSSv0jy29baPRM8IwAAAABT1LjOfKqqI5NckeS4JO9L8qThXY9M8rMkr5/Q6QAAAACY0hY6PlXVa5O8LckxSXZOUnPua63dmuT0JLtN9IAAAAAATF3jOfPp9UlOaa39bZIfj3H/T5NsMBFDAQAAADA9jCc+rZ/km/O5f3aS1RZvHAAAAACmk/HEp7uSPGo+9z8xyc2LNQ0AAAAA08p44tN5SfYc646qemSSVyb57kQMBQAAAMD0MJ749OEk21bVSUk2H277i6raJck5SdZK8pGJHQ8AAACAqWzmwu7YWvtWVb0uyceS7DPcfNLw+z1J/qa19v0Jng8AAACAKWyh41OStNaOq6rTk7w0yYZJKsmVSb7YWruuw3wAAAAATGHjik9J0lr7bZKPd5gFAAAAgGlmPGs+AQAAAMC4LPSZT1X1XwuxW2utPW8x5gEAAABgGhnPZXdPStLG+PnHZnAG1Y1J/jhBcwEAAAAwDYzn0+7WHmt7VS2T5C1JDkyy3cSMBQAAAMB0sNhrPrXW7m6tfTDJD5P80+KPBAAAAMB0MZELjn8nyS4TeDwAAAAApriJjE/rJHnEBB4PAAAAgCluPJ9294R53LVKkh2TvCnJORMwEwAAAADTxHg+7e7qPPjT7uaoJP+XQYACAAAAgCTji0/vy4PjU0vyhyRXJPlWa+3+iRoMAAAAgKlvoeNTa+2wjnMAAAAAMA0t1ILjVbV8Vf28qv628zwAAAAATCMLFZ9aa7cnWTXJ7X3HAQAAAGA6Waj4NPSDJLN6DQIAAADA9DOe+HRokpdV1YFVVb0GAgAAAGD6mO+C41X1hCSzW2t3JvmnJDcl+dckH6qqnye5Y9SPtNba87pMCgAAAMCUs6BPu/tlklck+UKSJyVpSX49vG+NjnMBAAAAMA0sKD7V8CuttbW7TwMAAADAtDKeNZ8AAAAAYFzEJwAAAAC6WdBld0ny7KpamP2SJK21zyzGPAAAAABMIwsTlV4z/FqQymBBcvEJAAAAgCQLF5+OS/KD3oMAAAAAMP0sTHz639ba57tPAgAAAMC0Y8FxAAAAALoRnwAAAADoRnwCAAAAoJv5rvnUWhOnAAAAAFhk4hIAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3UxqfKqqXavq8qq6qqoOnc9+W1fVfVX1kiU5HwAAAACLZ9LiU1XNSHJMkucn2TjJy6tq43nsd2SSs5bshAAAAAAsrsk88+lpSa5qrf2itXZPkpOT7DHGfm9M8uUkNyzJ4QAAAABYfJMZn9ZMcs2I29cOt81VVWsm2TPJsfM7UFW9pqouqKoLZs+ePeGDAgAAALBoJjM+1Rjb2qjbRyV5e2vtvvkdqLV2XGttVmtt1uqrrz5R8wEAAACwmGZO4mNfm+TxI26vleT6UfvMSnJyVSXJakn+sqruba2dukQmBAAAAGCxTGZ8Oj/JelW1TpLrkuydZJ+RO7TW1pnz56o6IcnXhCcAAACAqWPS4lNr7d6qOjiDT7GbkeT41tqlVXXQ8P75rvMEAAAAwEPfZJ75lNbamUnOHLVtzOjUWjtgScwEAAAAwMSZzAXHAQAAAJjmxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKAb8QkAAACAbsQnAAAAALoRnwAAAADoRnwCAAAAoBvxCQAAAIBuxCcAAAAAuhGfAAAAAOhGfAIAAACgG/EJAAAAgG7EJwAAAAC6EZ8AAAAA6EZ8AgAAAKCbSY1PVbVrVV1eVVdV1aFj3L9vVf10+PW9qtpiMuYEAAAAYNFMWnyqqhlJjkny/CQbJ3l5VW08ardfJtmutbZ5ksOTHLdkpwQAAABgcUzmmU9PS3JVa+0XrbV7kpycZI+RO7TWvtdau2l48wdJ1lrCMwIAAACwGCYzPq2Z5JoRt68dbpuXv07y9a4TAQAAADChZk7iY9cY29qYO1btkEF8etY87n9NktckyROe8ISJmg8AAACAxTSZZz5dm+TxI26vleT60TtV1eZJ/jXJHq213491oNbaca21Wa21WauvvnqXYQEAAAAYv8mMT+cnWa+q1qmqRyTZO8npI3eoqick+UqSV7bWrpiEGQEAAABYDJN22V1r7d6qOjjJWUlmJDm+tXZpVR00vP/YJO9JsmqST1ZVktzbWps1WTMDAAAAMD6TueZTWmtnJjlz1LZjR/z51UlevaTnAgAAAGBiTOZldwAAAABMc+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDfiEwAAAADdiE8AAAAAdCM+AQAAANCN+AQAAABAN+ITAAAAAN2ITwAAAAB0Iz4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAAADQjfgEAAAAQDczJ/PBq2rXJB9LMiPJv7bWjhh1fw3v/8skdyQ5oLX2oyU+KAAAAPP1pz/9Kddee23uuuuuyR4FWAyPfOQjs9Zaa2XppZeesGNOWnyqqhlJjkmyU5Jrk5xfVae31n42YrfnJ1lv+LVNkk8NvwMAAPAQcu2112aFFVbI2muvncF5BMBU01rL73//+1x77bVZZ511Juy4k3nZ3dOSXNVa+0Vr7Z4kJyfZY9Q+eyT5TBv4QZKVquqxS3pQAAAA5u+uu+7KqquuKjzBFFZVWXXVVSf8DMbJjE9rJrlmxO1rh9vGu0+q6jVVdUFVXTB79uwJHxQAAIAFE55g6uvx73gy49NYz6Ytwj5prR3XWpvVWpu1+uqrT8hwAAAATC0zZszIlltumU033TS77bZbbr755rn3XXrppXnuc5+b9ddfP+utt14OP/zwtPbnXy+//vWvZ9asWdloo42y4YYb5q1vfeskPIN5O+ecc/LCF75wsY9z7LHH5jOf+cx8H+d73/veQu8/2p133pntttsu991332LN2dMHP/jBrLvuutlggw1y1llnjbnPT37yk2y77bbZbLPNsttuu+XWW29Nktxzzz058MADs9lmm2WLLbbIOeecM/dntt9++2ywwQbZcssts+WWW+aGG25IkhxyyCFzt62//vpZaaWV5v7MiSeemPXWWy/rrbdeTjzxxLnb995771x55ZUT/+QnyWQuOH5tksePuL1WkusXYZ9p6+L9L57sEQAAAKaMZZddNhdddFGSZP/9988xxxyTd77znbnzzjuz++6751Of+lR23nnn3HHHHdlrr73yyU9+Mm94wxtyySWX5OCDD84ZZ5yRDTfcMPfee2+OO+64CZ3t3nvvzcyZk/qZX0mSgw46aL73n3POOVl++eXzjGc8Y6H2H+3444/Pi1/84syYMWOh9m+tpbWWpZZaMufG/OxnP8vJJ5+cSy+9NNdff3123HHHXHHFFQ+a99WvfnU+8pGPZLvttsvxxx+fD3/4wzn88MPz6U9/Okly8cUX54Ybbsjzn//8nH/++XPn/9znPpdZs2Y94Fj//M//PPfPH//4x/PjH/84SfKHP/wh733ve3PBBRekqvLUpz41u+++e1ZeeeW87nWvy4c+9KG5jzfVTeY7//wk61XVOkmuS7J3kn1G7XN6koOr6uQMFhq/pbX2myU7JgAAAAtr7UPP6Hr8q494wULtt+222+anP/1pkuTzn/98nvnMZ2bnnXdOkiy33HL5xCc+ke233z5veMMb8qEPfSjvfOc7s+GGGyZJZs6cmde//vUPOubtt9+eN77xjXNjwT/8wz9kr732yvLLL5/bb789SfKf//mf+drXvpYTTjghBxxwQFZZZZX8+Mc/zpZbbplTTjklF1100dwzX9Zdd91897vfzVJLLZWDDjoov/71r5MkRx11VJ75zGcu1PP8whe+kA984ANpreUFL3hBjjzyyCTJv/3bv+XII4/M4x73uKy33npZZpll8olPfCKHHXZYll9++bz1rW/N0UcfnWOPPTYzZ87MxhtvnCOOOCLHHntsZsyYkc9+9rP5+Mc/nm9/+9tz97/qqqty0EEHZfbs2ZkxY0a+9KUv5clPfvID5vnc5z6Xz3/+83Nfrz322CM33XRT/vSnP+X9739/9thjj1x99dV5/vOfnx122CHf//73c+qpp+aLX/xivvjFL+buu+/Onnvumfe+971Jkhe96EW55pprctddd+XNb35zXvOa1yzU6zIvp512Wvbee+8ss8wyWWeddbLuuuvmvPPOy7bbbvuA/S6//PI85znPSZLstNNO2WWXXXL44YfnZz/7WZ73vOclSR7zmMdkpZVWygUXXJCnPe1pC/X4X/jCF+Y+t7POOis77bRTVllllbmP841vfCMvf/nL8+xnPzsHHHDAQyZaLq5JewattXur6uAkZyWZkeT41tqlVXXQ8P5jk5yZ5C+TXJXkjiQHTta8AAAATA333Xdfvv3tb+ev//qvkwwuuXvqU5/6gH2e/OQn5/bbb8+tt96aSy65JP/v//2/BR738MMPz6Mf/ehcfPHgKpWbbrppgT9zxRVX5Fvf+lZmzJiR+++/P6ecckoOPPDA/PCHP8zaa6+dNdZYI/vss08OOeSQPOtZz8qvf/3r7LLLLrnssssWeOzrr78+b3/723PhhRdm5ZVXzs4775xTTz01T3va03L44YfnRz/6UVZYYYU897nPzRZbbPGgnz/iiCPyy1/+Mssss0xuvvnmrLTSSjnooIPmxqYk+fa3vz13/3333TeHHnpo9txzz9x11125//77H3C8e+65J7/4xS+y9tprJ0ke+chH5pRTTsmKK66YG2+8MU9/+tOz++67JxnEnX//93/PJz/5yZx99tm58sorc95556W1lt133z3nnntunvOc5+T444/PKquskjvvvDNbb7119tprr6y66qoPeNxDDjkk//3f//2g57f33nvn0EMPfcC26667Lk9/+tPn3l5rrbVy3XXXPehnN91005x++unZY4898qUvfSnXXDNYjnqLLbaYG7CuueaaXHjhhbnmmmvmxqcDDzwwM2bMyF577ZV3vetdD1g/6Ve/+lV++ctf5rnPfe7cWR7/+D9f7DVylqWWWirrrrtufvKTnzzovTsVTWo+a62dmUFgGrnt2BF/bknesKTnAgAAYOq58847s+WWW+bqq6/OU5/61Oy0005JBpd2zWsR5fEsrvytb30rJ5988tzbK6+88gJ/5qUvfencS7r+6q/+Ku973/ty4IEH5uSTT85f/dVfzT3uz372s7k/c+utt+a2227LCiusMN9jn3/++dl+++0zZ+3jfffdN+eee26SZLvttpt7Rs1LX/rSXHHFFQ/6+c033zz77rtvXvSiF+VFL3rRfB/rtttuy3XXXZc999wzySAsjXbjjTc+YD2j1lre8Y535Nxzz81SSy2V6667Lr/73e+SJE984hPnRqCzzz47Z599drbaaqskgzOmrrzyyjznOc/J0UcfnVNOOSVJcs011+TKK698UHwaeVnbgoxc52uOsd4Dxx9/fN70pjflfe97X3bfffc84hGPSJK86lWvymWXXZZZs2bliU98Yp7xjGfMPTPpc5/7XNZcc83cdttt2WuvvXLSSSdlv/32m3vMk08+OS95yUvmvh8WNMtjHvOYXH/99eITAAAAPFTMWfPplltuyQtf+MIcc8wxedOb3pRNNtlkbpSZ4xe/+EWWX375rLDCCtlkk01y4YUXjnl20Ejzilgjt43+iPpHPepRc/+87bbb5qqrrsrs2bNz6qmn5l3veleS5P7778/3v//9LLvssuN6vmPFi/ltH+2MM87Iueeem9NPPz2HH354Lr300nE/1kjLLrvsA57/5z73ucyePTsXXnhhll566ay99tpz7x/5urTW8vd///d57Wtf+4DjnXPOOfnWt76V73//+1luueWy/fbbP+j1TcZ35tNaa6019yymJLn22mvzuMc97kE/u+GGG+bss89OMjh77YwzBpeTzpw58wGx6xnPeEbWW2+9JMmaa66ZJFlhhRWyzz775LzzzntQfDrmmGMeMMvIBcuvvfbabL/99nNv33XXXeN+TzxUiU8AAABMmIVdk6mnRz/60Tn66KOzxx575HWve1323XfffOADH8i3vvWt7Ljjjrnzzjvzpje9KX/3d3+XJHnb296WF7/4xXnWs56V9ddfP/fff3+OOuqovOUtb3nAcXfeeed84hOfyFFHHZVkcNndyiuvnDXWWCOXXXZZNthgg5xyyinzPGOpqrLnnnvmLW95SzbaaKO5Z/DMOe7b3va2JMlFF12ULbfccoHPc5tttsmb3/zm3HjjjVl55ZXzhS98IW984xsza9asHHLIIbnpppuywgor5Mtf/nI222yzB/zs/fffn2uuuSY77LBDnvWsZ+Xzn/98br/99qywwgpzP9ltpBVXXDFrrbVWTj311LzoRS/K3Xffnfvuuy/LLbfc3H1WXnnl3HfffbnrrrvyyEc+Mrfcckse85jHZOmll85///d/51e/+tWYz2OXXXbJu9/97uy7775Zfvnlc91112XppZfOLbfckpVXXjnLLbdc/u///i8/+MEPxvz58Zz5tPvuu2efffbJW97yllx//fW58sorx1yv6YYbbshjHvOY3H///Xn/+98/d+H1O+64I621POpRj8o3v/nNuetl3Xvvvbn55puz2mqr5U9/+lO+9rWvZccdd5x7vMsvvzw33XTTA9aW2mWXXfKOd7xj7uWbZ599dj74wQ/Ovf+KK67IJptsstDP7aFsySwnDwAAAEvQVlttlS222CInn3xyll122Zx22ml5//vfnw022CCbbbZZtt566xx88MFJBpefHXXUUXn5y1+ejTbaKJtuuml+85sHf9bVu971rtx0003ZdNNNs8UWW8w92+aII47IC1/4wjz3uc/NYx/72PnO9Vd/9Vf57Gc/O/eSuyQ5+uijc8EFF2TzzTfPxhtvnGOPPXbMn/32t7+dtdZaa+7X1VdfnQ9+8IPZYYcdssUWW+QpT3lK9thjj6y55pp5xzvekW222SY77rhjNt544zz60Y9+wLHuu+++vOIVr8hmm22WrbbaKoccckhWWmml7LbbbjnllFOy5ZZb5n//938f8DMnnXRSjj766Gy++eZ5xjOekd/+9rcPmnHnnXfOd77znSSDywAvuOCCzJo1K5/73OfmLug+1s/ss88+2XbbbbPZZpvlJS95SW677bbsuuuuuffee7P55pvn3e9+9wPWalpUm2yySV72spdl4403zq677ppjjjlm7mVwr371q3PBBRckGSwMvv7662fDDTfM4x73uBx44GAJ6htuuCFPecpTstFGG+XII4/MSSedlCS5++67s8suu2TzzTfPlltumTXXXDN/8zd/M/dxv/CFL2Tvvfd+wFlyq6yySt797ndn6623ztZbb533vOc9cy+V/N3vfpdll112ge+nqaIW9nS8qWLWrFltzpsFAACAJeOyyy7LRhttNNljMHT77bdn+eWXz7333ps999wzr3rVq+au19TTj3/84/zTP/3T3CjDovnnf/7nrLjiinMXzV/Sxvr3XFUXttZmLcrxnPkEAAAA08xhhx2WLbfcMptuumnWWWedBS4oPlG22mqr7LDDDrnvvvuWyONNVyuttFL233//yR5jwjjzCQAAgMXmzCeYPpz5BAAAAMCUIT4BAAAA0I34BAAAAEA34hMAAAAA3YhPAAAAAHQjPgEAADAtzJgxI1tuuWU23XTT7Lbbbrn55pvn3nfppZfmuc99btZff/2st956OfzwwzPy09+//vWvZ9asWdloo42y4YYb5q1vfeskPIN5u+OOO7Lvvvtms802y6abbppnPetZuf3227P99tvnrLPOesC+Rx11VF7/+tfn6quvTlXl3e9+99z7brzxxiy99NI5+OCDx3ycU089Ne973/u6PpfF8Yc//CE77bRT1ltvvey000656aabxtzvYx/7WDbddNNssskmOeqoo+Zu/8lPfpJtt902m222WXbbbbfceuutc+/76U9/mm233TabbLJJNttss9x1111Jkl133TVbbLFFNtlkkxx00EG577775v7MF7/4xWy88cbZZJNNss8++yRJZs+enV133bXDs5+6Zk72AAAAAEwjhz268/Fvmeddyy67bC666KIkyf77759jjjkm73znO3PnnXdm9913z6c+9ansvPPOueOOO7LXXnvlk5/8ZN7whjfkkksuycEHH5wzzjgjG264Ye69994cd9xxEzr2vffem5kzF/1X8I997GNZY401cvHFFydJLr/88iy99NJ5+ctfnpNPPjm77LLL3H1PPvnkfPjDH06SPOlJT8rXvva1HH744UmSL33pS9lkk03m+Tgf+tCHcvrppy/0XIv7vMbriCOOyPOe97wceuihOeKII3LEEUfkyCOPfMA+l1xyST796U/nvPPOyyMe8YjsuuuuecELXpD11lsvr371q/ORj3wk2223XY4//vh8+MMfzuGHH5577703r3jFK3LSSSdliy22yO9///ssvfTSSQaBacUVV0xrLS95yUvypS99KXvvvXeuvPLKfPCDH8x3v/vdrLzyyrnhhhuSJKuvvnoe+9jH5rvf/W6e+cxnLrHX5qHMmU8AAABMO9tuu22uu+66JMnnP//5PPOZz8zOO++cJFluueXyiU98IkcccUSSQXB55zvfmQ033DBJMnPmzLz+9a9/0DFvv/32HHjggdlss82y+eab58tf/nKSZPnll5+7z3/+53/mgAMOSJIccMABectb3pIddtghb3vb27L22ms/4GysddddN7/73e8ye/bs7LXXXtl6662z9dZb57vf/e6DHvs3v/lN1lxzzbm3N9hggyyzzDJ5yUtekq997Wu5++67kyRXX311rr/++jzrWc9KMghyG220US644IIkyX/8x3/kZS972Ziv2RVXXJFlllkmq622WpLkq1/9arbZZptstdVW2XHHHfO73/0uSXLYYYflNa95TXbeeefst99+85z/vPPOyzOe8YxstdVWecYznpHLL7987L+scTjttNOy//77JxkExlNPPfVB+1x22WV5+tOfnuWWWy4zZ87Mdtttl1NOOSXJ/2/v7uN0LPP/j78+GYXctcKX/HapMDPmztyQcq+Z3DVIdlhtsrX9aonSDZXd9UWFFFnaviVLoemb3JRky12iO4YwUUMlTeZhZRmEGHN8/zivuXbGXMNlzBij9/PxuB7XXOd5nOfxOc+5jgc+juNzekm7tm3bApCYmOj/Hb733ntERUURHR0NQK1atahQoQIA1atXB7xE2/HjxzEzAF566SUGDRrEFVdcAUCdOnX8MfTs2ZM5c+ac8/VeLJR8EhERERERkYvKyZMnWb58OcnJyYC35C4uLq5Am2uuuYbDhw9z8OBB0tPTC+0PZMyYMdSoUYMtW7awefNmOnbseMZjMjIyWLZsGZMmTaJHjx7+JMinn35Kw4YNqVu3LkOHDuWBBx5g3bp1vPnmm9x1112FzvOHP/yB8ePH06pVK0aOHMn27dsBL0nSokULli5dCniznlJSUvwJEoC+ffuSmppKZmYmFSpUoH79+gFjXbt2LbGxsf7PrVu35pNPPmHjxo307duXCRMm+PelpaWxaNEi5s6dW2T8oaGhrF69mo0bNzJ69Ggee+yxQn0eOnSImJiYgK+tW7cWar9nzx7q1asHQL169fyzjfKLiIhg9erV7Nu3jyNHjrBkyRK+//57/768mV1vvPGGf3tGRgZmxk033URsbGyBawW46aabqFOnDtWqVePWW2/1H5ORkcENN9zAdddd5/8dAMTHx/Phhx8GvM+/RFp2JyIiIiIiIheFo0ePEhMTw86dO4mLiyMxMREA51yBZEx+RW0PZNmyZaSmpvo/5814OZ0+ffr4Z9CkpKQwevRoBg4c6E8S5Z03f6Ll4MGDHDp0iGrVqvm3xcTE8M033/Dee++xbNkyEhIS+PjjjwkLC/MvvevRowepqanMmDGjQAydO3fmz3/+M3Xr1vX3GUhWVha1a9f2f87MzCQlJYWsrCyOHz9Oo0aN/PuSk5OpXLnyaePPzs5mwIABbN++HTPjxIkThfqsVq2af6lkSQkLC2P48OEkJiZStWpVoqOj/UsDZ8yYwZAhQxg9ejTJyclceumlgDerac2aNaxbt44qVarQqVMn4uLi6NSpEwD//Oc/OXbsGP3792fFihUkJiaSk5PD9u3bWbVqFZmZmbRp04b09HRq1qxJnTp12L17d4leV3mm5JOIiIiIiIiUnNPUZCpteTWfsrOz6d69O9OmTWPIkCE0a9aM1atXF2j7zTffULVqVapVq0azZs1IS0vzL7kqSlFJrPzb8opU57n88sv9P7dq1YodO3awd+9eFi5cyMiRIwHIzc3l448/9idzilK1alVuueUWbrnlFi655BKWLFlCWFgYPXv2ZNiwYWzYsIGjR48WmL0EcOmllxIXF8czzzzDF198wdtvvx3w/JUrVyY7+z+/v/vuu49hw4aRnJzMqlWrGDVqVMDrKir+++67jw4dOrBgwQJ27txJ+/btC/V56NAh2rRpEzCeuXPnEh4eXmBb3bp1ycrKol69emRlZRVY6pbfnXfeyZ133gnAY489RoMGDQBvNtZ7770HeDOX3nnnHQAaNGhAu3bt/EsOu3btyoYNG/zJJ4BKlSqRnJzMokWLSExMpEGDBlx33XVUrFiRRo0a0bRpU7Zv305CQgLHjh074+/zl0TL7kREREREROSiUqNGDaZMmcLEiRM5ceIE/fv3Z82aNSxbtgzwZkgNGTKERx55BICHH36YJ598koyMDMBLpjz77LOFzpuUlMTUqVP9n/OetFa3bl22bdtGbm6uf1ldIGZGr169GDZsGGFhYdSqVSvgeQPNBFq7dq2/v+PHj7N161Z+85vfAF5Sqn379vzhD3+gX79+Aft+8MEHGT9+vL/PQMLCwtixY4f/c3Z2tr/O1KxZs4o8rqj48x8/c+bMgMfmzXwK9Do18QTejKu8WGbNmkWPHj0CnjdvOd6uXbuYP3++/77kbc/NzWXs2LHcc889gLesbvPmzRw5coScnBw++OADwsPDOXz4MFlZWYA3O2rJkiX+2mA9e/Zk5cqVgPcUwYyMDK6++mrAS2xFREQUec9+aZR8EhERERERkYtO8+bNiY6OJjU1lcqVK7No0SLGjh1L06ZNiYyMJCEhgcGDBwMQFRXF5MmT6devH2FhYURERPgTDvmNHDmS/fv3ExERQXR0tD/xMG7cOLp3707Hjh399YiKkpKSwuzZswssf5syZQrr168nKiqK8PBwXnjhhULHff3117Rr147IyEiaN29OfHw8vXv39u/v168fmzZtom/fvgH7bdasmb9Qd1Hatm3Lxo0bcc4BXmHxPn360KZNG/+MoECKiv+RRx7h0Ucf5YYbbuDkyZOn7TtYI0aM4P3336dx48a8//77jBgxAoDdu3fTtWtXf7vevXsTHh7OzTffzLRp0/xLJF977TWaNGlCaGgo9evXZ+DAgYC3hHLYsGEkJCQQExNDbGws3bp146effiI5OdlfjLxOnToFEla1atUiPDycDh068PTTT/uTeytXrqRbt24lcs0XA8v7Ul0s4uPjXV4VfxERERERETk/tm3bRlhYWFmHIedo6NCh3Hzzzdx4441lHUq51rZtWxYtWhRUXbALUaDxbGZpzrn44pxPM59EREREREREBPDqIx05cqSswyjX9u7dy7Bhw8pt4qk0KPkkIiIiIiIiIoBXvyo5ObmswyjXateuTc+ePcs6jAuKkk8iIiIiIiIiIlJqlHwSEREREREREZFSo+STiIiIiIiIiIiUGiWfRERERERERESk1Cj5JCIiIiIiIheFChUqEBMTQ0REBDfffDMHDhzw7/viiy/o2LEjTZo0oXHjxowZMwbnnH//u+++S3x8PGFhYYSGhvLQQw+VwRWc3meffUb79u1p3LgxsbGxdOvWjS1btpR6vy+88AKvvPJKiZzLzHjwwQf9nydOnMioUaMAGDVqFFdddRUxMTGEhoZy7733kpubG/A8kydPLrGYSsO3335Ly5Ytady4MSkpKRw/fjxgu+HDhxMREUFERASvv/66f/vy5cuJjY0lJiaG1q1bs2PHDgD2799Pr169iIqKokWLFqSnpxc438mTJ2nevDndu3f3b3v44YcJDQ0lKiqKXr16+cfFli1buOOOO0r2wosQcl56ERERERERkV+EyFmRpXr+LQOKTrZUrlyZzz//HIABAwYwbdo0Hn/8cY4ePUpycjJ///vfSUpK4siRI/Tu3Zvnn3+eQYMGkZ6ezuDBg3nnnXcIDQ0lJyeHF198sUTjzsnJISSk+P8E37NnD7/97W+ZO3cu119/PQBr1qzh66+/JjKydO/5PffcU2Lnuuyyy5g/fz6PPvooV155ZaH9DzzwAA899BC5ubm0bduWDz74gA4dOhRok5OTw4wZM9iwYUPQ/Z7r/T9bw4cP54EHHqBv377cc889vPzyy9x7770F2rzzzjts2LCBzz//nJ9//pl27drRpUsXqlevzr333suiRYsICwvj+eefZ+zYscycOZMnn3ySmJgYFixYwJdffsmgQYNYvny5/5zPPfccYWFhHDx40L8tMTGRp556ipCQEIYPH85TTz3F+PHjiYyMJDMzk127dvHrX/+6VO+HZj6JiIiIiIjIRadVq1b88MMPAMydO5cbbriBpKQkAKpUqcLUqVMZN24cABMmTODxxx8nNDQUgJCQEP70pz8VOufhw4cZOHAgkZGRREVF8eabbwJQtWpVf5t58+b5Z5PccccdDBs2jA4dOvDwww/TsGHDArOxrr32Wvbs2cPevXvp3bs3CQkJJCQksHbt2kJ9T506lQEDBvgTTwCtW7emZ8+e/r7mzZvn35cX0+HDh+nUqROxsbFERkayaNEiAH766Se6detGdHR0gVk3I0aMIDw8nKioKP/sr1GjRjFx4kQAXnrpJRISEoiOjqZ3794cOXLE3/+QIUO4/vrrufrqqwvEkl9ISAh33303kyZNCrg/z/Hjxzl27BhXXHFFoX0rVqwgNjbWn0w6XUx593/48OF8/fXXdO7cmbi4ONq0acOXX34JwNtvv03Lli1p3rw5N954I3v27DltbGfinGPFihXceuutgJcIXbhwYaF2W7dupV27doSEhHD55ZcTHR3N0qVLAW+GWF4CKTs7m/r16/uP6dSpEwChoaHs3LnTH29mZibvvPMOd911V4F+kpKS/PfquuuuIzMz07/v5ptvJjU19ZyuNxhKPomIiIiIiMhF5eTJkyxfvpzk5GTAW3IXFxdXoM0111zD4cOHOXjwIOnp6YX2BzJmzBhq1KjBli1b2Lx5Mx07djzjMRkZGSxbtoxJkybRo0cPFixYAMCnn35Kw4YNqVu3LkOHDuWBBx5g3bp1vPnmm4WSB3nXEBsbG8zlF1CpUiUWLFjAhg0bWLlyJQ8++CDOOZYuXUr9+vXZtGkT6enpdO7cmX//+98sWLCAL774gs2bNzNy5MhC57vllltYt24dmzZtIiwsjJdfftm/LysrizVr1rB48WJGjBhRZEyDBg1izpw5ZGdnF9o3adIkYmJiqFevHk2aNCEmJqZQm7Vr1xb4fZ0uprz7/8wzz3D33Xfzt7/9jbS0NCZOnOhPMLZu3ZpPPvmEjRs30rdvXyZMmFCoz6+++oqYmJiAr/wJRYB9+/ZRs2ZNf8KnQYMG/kRoftHR0bz77rscOXKEH3/8kZUrV/L9998DMH36dLp27UqDBg149dVX/fczOjqa+fPnA94yzO+++86fTLr//vuZMGECl1xSdKpnxowZdOnSxf85Pj6eDz/8sMj2JUXL7kREREREROSicPToUWJiYti5cydxcXEkJiYC3kwUMwt4TFHbA1m2bFmBWSKBZuWcqk+fPlSoUAGAlJQURo8ezcCBA0lNTSUlJcV/3q1bt/qPOXjwIIcOHaJatWpFnrdly5YcPHiQpKQknnvuuSLbOed47LHHWL16NZdccgk//PADe/bsITIykoceeojhw4fTvXt32rRpQ05ODpUqVeKuu+6iW7duBeoG5UlPT2fkyJEcOHCAw4cPc9NNN/n39ezZk0suuYTw8PDTzh6qXr06t99+O1OmTKFy5coF9uUtuztx4gS33norqamp9O3bt0CbrKwswsLCgoop7/4fPnyYjz76iD59+vj3/fzzz4A3YyglJYWsrCyOHz9Oo0aNCsXctGlT/5LOM8lfSyxPoO9ZUlIS69at4/rrr6d27dq0atXKn7CaNGkSS5YsoWXLljz99NMMGzaM6dOnM2LECIYOHUpMTAyRkZE0b96ckJAQFi9eTJ06dYiLi2PVqlUB43riiScICQmhf//+/m116tRh9+7dQV3XuVDySURERERERErM6Woylba8mk/Z2dl0796dadOmMWTIEJo1a8bq1asLtP3mm2+oWrUq1apVo1mzZqSlpREdHX3a8xeVxMq/7dixYwX2XX755f6fW7VqxY4dO9i7dy8LFy70zyzKzc3l448/LpSIya9Zs2Zs2LCBHj16AN7MqXnz5rF48WLAW86WV5zbOecvcD1nzhz27t1LWloaFStWpGHDhhw7dowmTZqQlpbGkiVLePTRR0lKSuIvf/kLn332GcuXLyc1NZWpU6eyYsWKAnHccccdLFy4kOjoaGbOnFkg0XHZZZcVuFenc//99xMbG8vAgQMD7q9YsSKdO3dm9erVhZJPlStXLnCfTxdT3v3Pzc2lZs2aARNI9913H8OGDSM5OZlVq1b5C6Dn99VXX/mThadatWoVNWvW9H++8sorOXDggL/OVGZmpn/Z3Kkef/xxHn/8cQB+97vf0bhxY/bu3cumTZto2bIl4CUtO3fuDHiJu3/84x+Ad48bNWpEo0aNSE1N5a233mLJkiUcO3aMgwcPcttttzF79mwAZs2axeLFi1m+fHmh7+vpvnclRcvuRERERERE5KJSo0YNpkyZwsSJEzlx4gT9+/dnzZo1LFu2DPBmSA0ZMoRHHnkE8J4G9uSTT5KRkQF4iYpnn3220HmTkpKYOnWq//P+/fsBqFu3Ltu2bSM3N9e/rC4QM6NXr14MGzaMsLAwatWqFfC8gRIkgwYNYubMmXz00Uf+bXm1jQAaNmxIWloaAIsWLeLEiROAVy+oTp06VKxYkZUrV/Ldd98BsHv3bqpUqcJtt93GQw89xIYNGzh8+DDZ2dl07dqVyZMnB4zj0KFD1KtXjxMnTjBnzpwir/VMfvWrX/Hb3/62wBK5/JxzfPTRR1xzzTWF9oWFhfmf/hZsTNWrV6dRo0a88cYb/vNv2rQJ8O7RVVddBXhJmkDyZj4FeuVPPIH3e+7QoYO/7tWsWbP8ScP8Tp48yb59+wDYvHkzmzdvJikpiSuuuILs7Gz/9/H999/3z/Q6cOCAP7E4ffp02rZtS/Xq1XnqqafIzMxk586dpKam0rFjR3/iaenSpYwfP5633nqLKlWqFIghIyODiIiIgNdckpR8EhERERERkYtO8+bNiY6OJjU1lcqVK7No0SLGjh1L06ZNiYyMJCEhgcGDBwMQFRXF5MmT6devH2FhYURERJCVlVXonCNHjmT//v1EREQQHR3NypUrARg3bhzdu3enY8eO1KtX77RxpaSkMHv27AKzaKZMmcL69euJiooiPDycF154odBx//Vf/8Xrr7/Oo48+yrXXXsv111/PvHnz/Nfwxz/+kQ8++IAWLVrw6aef+mf89O/fn/Xr1xMfH8+cOXP8RdW3bNlCixYtiImJ4YknnmDkyJEcOnSI7t27ExUVRbt27QIWBR8zZgwtW7YkMTHRf67ievDBB/nxxx8LbMur+RQREUFOTk7Awu9dunQpMJMt2JjmzJnDyy+/THR0NM2aNfMXXx81ahR9+vShTZs2AZ/AVxzjx4/n2Wef5dprr2Xfvn3ceeedAKxfv95f0+vEiRO0adOG8PBw7r77bmbPnk1ISAghISG89NJL9O7dm+joaF599VWefvppALZt20azZs0IDQ3l3XffPe2SyzyDBw/m0KFDJCYmEhMTU+DphStXrqRbt24lcs2nY2eaClfexMfHu/Xr15d1GCIiIiIiIr8o27ZtK1CHR6Q09erViwkTJtC4ceOyDqXc+vnnn2nXrh1r1qzx15rKE2g8m1macy6+OH1p5pOIiIiIiIiIlCvjxo0LODtNgrdr1y7GjRtXKPFUGlRwXERERERERETKlaZNm9K0adOyDqNca9y48XmbOaaZTyIiIiIiIlIiLrayLiK/RKUxjpV8EhERERERkXNWqVIl9u3bpwSUSDnmnGPfvn1UqlSpRM+rZXciIiIiIiJyzho0aEBmZiZ79+4t61BE5BxUqlSJBg0alOg5lXwSERERERGRc1axYkUaNWpU1mGIyAVIy+5ERERERERERKTUKPkkIiIiIiIiIiKlRsknEREREREREREpNXaxPYnAzPYC35V1HCXsSuDHsg5C5CKiMSVScjSeREqWxpRIydKYEik5TZ1z1Ypz4EVXcNw5V7usYyhpZrbeORdf1nGIXCw0pkRKjsaTSMnSmBIpWRpTIiXHzNYX91gtuxMRERERERERkVKj5JOIiIiIiIiIiJQaJZ/KhxfLOgCRi4zGlEjJ0XgSKVkaUyIlS2NKpOQUezxddAXHRURERERERETkwqGZTyIiIiIiIiIiUmqUfLqAmFlnM/vKzHaY2YgA+83Mpvj2bzaz2LKIU6S8CGJM9feNpc1m9pGZRZdFnCLlwZnGU752CWZ20sxuPZ/xiZQ3wYwpM2tvZp+b2Rdm9sH5jlGkvAji73w1zOxtM9vkG08DyyJOkfLAzGaY2b/MLL2I/cXKSyj5dIEwswrANKALEA70M7PwU5p1ARr7XncDfz+vQYqUI0GOqW+Bds65KGAMqgkgElCQ4ymv3Xjgn+c3QpHyJZgxZWY1geeBZOdcM6DP+Y5TpDwI8s+oQcBW51w00B54xswuPa+BipQfM4HOp9lfrLyEkk8XjhbADufcN86540Aq0OOUNj2AV5znE6CmmdU734GKlBNnHFPOuY+cc/t9Hz8BGpznGEXKi2D+jAK4D3gT+Nf5DE6kHApmTP0OmO+c2wXgnNO4EgksmPHkgGpmZkBV4N9AzvkNU6R8cM6txhsjRSlWXkLJpwvHVcD3+T5n+radbRsR8ZzteLkTeLdUIxIpv844nszsKqAX8MJ5jEukvArmz6gmwBVmtsrM0szs9vMWnUj5Esx4mgqEAbuBLcBQ51zu+QlP5KJTrLxESKmFI2fLAmw79VGEwbQREU/Q48XMOuAln1qXakQi5Vcw42kyMNw5d9L7j2UROY1gxlQIEAd0AioDH5vZJ865jNIOTqScCWY83QR8DnQErgHeN7MPnXMHSzk2kYtRsfISSj5dODKB/5fvcwO8zPzZthERT1DjxcyigOlAF+fcvvMUm0h5E8x4igdSfYmnK4GuZpbjnFt4XiIUKV+C/Xvfj865n4CfzGw1EA0o+SRSUDDjaSAwzjnngB1m9i0QCnx2fkIUuagUKy+hZXcXjnVAYzNr5Ct+1xd465Q2bwG3+6rLXwdkO+eyznegIuXEGceUmf0amA/8Xv+TLHJaZxxPzrlGzrmGzrmGwDzgT0o8iRQpmL/3LQLamFmImVUBWgLbznOcIuVBMONpF94sQsysLtAU+Oa8Rily8ShWXkIzny4QzrkcMxuM94SgCsAM59wXZnaPb/8LwBKgK7ADOIKXwReRAIIcU38BagHP+2Zr5Djn4ssqZpELVZDjSUSCFMyYcs5tM7OlwGYgF5junAv42GuRX7Ig/4waA8w0sy14S4aGO+d+LLOgRS5gZvYa3lMhrzSzTOCvQEU4t7yEeTMPRURERERERERESp6W3YmIiIiIiIiISKlR8klEREREREREREqNkk8iIiIiIiIiIlJqlHwSEREREREREZFSo+STiIiIiIiIiIiUGiWfREREpEyZ2Sgzc2bWsKxjOZ/O9rrN7A5f+/alGpiIiIhICVPySURERM6KmbX3JUGKel1X1jEGy8waBoj/iJmlm9lfzazyeY6nvS8pVfN89hssM1t1yr06YWa7zex1M4s4x3P3NLNRJRSqiIiIXEBCyjoAERERKbdeA5YE2L7jfAdSAt4HXvH9XBtIAUYB1wM3lVKfY4FxwM/5trUH/grMBA6c0v5VIBU4XkrxBOtn4C7fz5WBOGAg0NXM4p1zXxXzvD2BAXj3XURERC4iSj6JiIhIcW1wzs0u6yBKSEb+azGzvwGfAUlmluCcW1fSHTrncoCcs2h/EjhZ0nEUQ84pv/eXzGwr8BwwGLivbMISERGRC5WW3YmIiEiJM7MWZjbTzDJ8y9gOmdlaM+sV5PG/MrNJZva1mR0zs31mlmZmDwdom2Jma3x9HDGzT83s1nOJ35cYWuH7eG2+vu4ysw1mdtTMss3sPTNrHSCmbmb2gZn96Gu7y8zmm1mTfG0K1Hwys5l4s54Avs23tG2Ub3+Bmk9m1sX3eUigazCzj81sr5lVzLetsZm9amZZZnbczHaa2dNmdnmxb5Znue+98SkxBPU9MLNVeLOeOGVZ3x352tQzs7/77uVx33K/F82szjnGLiIiIqVMM59ERESkuKqY2ZWnbPvZOXcI6AWEAv8LfAfUwksuzDez/s65uWc49xtAW+B/gE1AFd/52gNP5zUys7HA48BS4M9Arq/vN8xssHNu2jlcX14i5UdfX+OBR/BmRD0GVAPuBlaaWQ/n3BJfu3bAW8AW4Cm85XP1gRvxElkZRfT3P0B1X/wP5PULbC6i/XtAFnA7MCX/DjNrDFwHTHHOnfBti8NLqB3w9fUDEA0MAW4ws3Z5bYvhGt/7v0/ZHuz34Am8/xRtA/w+3/Ef+WL/NfAxcCnwMvA13r28F+jgW+6XXczYRUREpJSZc66sYxAREZFyxDfzZmURu193zvU1s8udcz+dclwVYCNw0jkXnm/7KLwZP42cczvNrAZeguTvzrk/nSaOWCANeMo599gp+xYCHYGrfMmwos7REPgWL6Exwre5NtAfL6m1Ey950hDYhpcM6eicO+47vj6w1RfvNc65k2b2LF7yqK5z7l+n6bvAdRe1LV/7O4B/AB2cc6t8254GHgKaOee25ms7BhgJxDnnNvi2bQIuAxLy3xPfLKT5wEDn3Myi4vW1XQXE++4H/Kfm02TgN0C3vCScr/3ZfA9mAgOccxag30VAKyDWOZeZb3s88Akw1jk36nSxi4iISNnRsjsREREprheBxFNeYwHyJxzMrIqZ1cKbvbQCCDOz6qc571G8otYt85akFaE/4IBZZnZl/hfezKNqeAmLYNwJ7PW9tuIlnlYDSc65n4EegAET8hJPvuvcjVcc/DdAc9/mvBk4vc2stGeZz/K93563wcwMuA1Iz5d4igSigLnAZafcqzXAT0BSkH1ezn/u1S5gAd6MpAH5E09wzt+DvONqAN3xfqfHTol9J16B+2BjFxERkTKgZXciIiJSXNudc8sC7fDV4RmLl7QJVJOnJnAw0LHOueNmdj9eAetvzStmvQJY6Jxbnq9pGF5C6MvTxFj3DNeQZxEwFS+ZdQzY4Zzbk29/I9/7FwGOTfe9Xw2s952nB/A8MN7M1uAtC3zNObc3yHiC4pxLN7ONQH8ze8w5l4u3XLEhkL8+Vpjv/b99r0CCvVfHgJt9P/8KL/GVSID/1DyX70E+TX3nvtP3CuSbMwUtIiIiZUfJJxERESlRvpk37+ElPKYA6/BmA50EBgK/4wyzr51zL/iWWnUD2gG3AoPN7HXnXN+8rvCSRV0o+ilwgZJFgWQWlUjL11dQnHP7zCwBr35RIl4yaBLw32bW1Tn3cbDnCtIsvGVvHYFleMmgk8CcfG3y4n8GLxEWyP4g+zuZ/16Z2TxgMfCimW1wzm32bT/n78Epsc/mPzO9TnU0yNhFRESkDCj5JCIiIiUtCq+Q9Wjn3F/z7zCzu4I9iXMuC5gOTDezCsCrQD8ze8Y5tw7YDnQGdjnntpVY9IF97Xtvlu/nPHl1i/yzb5xzJ4FVvhdmFoVXn2okXkKtKMUpxjkXrwj77Wa2Fi9R977v/uXZ7ns/eYYk21lzzuWa2VC85YoT+c8SuLP9HhR17Tt8+y4t6dhFRETk/FDNJxERESlpebOQCswWMrMIvKefnZavNlCV/Nt8yZy8p779yvf+qu/9SV9y6tTzBFrmVVxv4SVAHjazivn6qIc3i+c7vCLaBHgCIHhLA4/yn9iLctj3fqZ2fr6lfO8Ct+DVwapO4RlCG/GWB95jZlefeg4zCzGzoPsMEMN2vCRYopm19m0+2+/BYd/+AnE45/YBS4BbzOy6ALGbmdUubuwiIiJS+jTzSUREREraNrzlbo/4kkhfAU2A/4+XAIk9w/FNgA/MbIGv/X68pVv34j2Z7kMA59w6M/srXg2jz83sDWA3UA/vCWxd8QphnzPn3Fe+J8s9Aqw2s9fxCprfDVQF+vsSZAAvmVkDvCVn3+E9ES7F1/6VM3T1ie99vJnNwauvlO6cSz/NMeAlm5LxltVl49Wwyh+/M7Pf49XO2mxmM/B+R1WAa/ESV4/iFU8vrifxCp3/N9CJs/8efAIMBp43s3eAE8Cnzrlv8X73a/Du/St4ybRL8Ops9cC7r6POIXYREREpRUo+iYiISIlyzp00s254S7AG4D0dLd33czRnTj59D8wAOgA9gcuAH4CXgPHOuSP5+hptZmnAEOB+X1//8vU3tMQuyutruJntAP4EjAOOA58Cv3POfZiv6avAHXjXWxuvoPZW4Fbn3Jtn6GOtmQ0H7sG73hC8ZM6Zkk+LgX/jzZia7pwrVAPJOfe5mTXHSzIl+/o4hPfEuJnA8lOPORu+BN3/An3NrJ1z7oOz/B68hvfEwL5AH7zk0kDgW+fc92YWBwzHSzbdhpeY+x54G/jfc4ldRERESpc5V5zSAiIiIiIiIiIiImemmk8iIiIiIiIiIlJqlHwSEREREREREZFSo+STiIiIiIiIiIiUGiWfRERERERERESk1Cj5JCIiIiIiIiIipUbJJxERERERERERKTVKPomIiIiIiIiISKlR8klEREREREREREqNkk8iIiIiIiIiIlJqlHwSEREREREREZFS839GNUuMUk0JtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_preds = log.predict_proba(X_test)\n",
    "svm_preds = svc.predict_proba(X_test)\n",
    "gaussian_preds = gaussianNB.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, log_preds[:,1])\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_preds[:,1])\n",
    "gaussian_fpr, gaussian_tpr, _ = roc_curve(y_test, gaussian_preds[:,1])\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "\n",
    "log_auc = auc(fpr, tpr)\n",
    "svm_auc = auc(svm_fpr, svm_tpr)\n",
    "gaussian_nb_auc = auc(gaussian_fpr, gaussian_tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'ROC curve Logistic (area = %0.5f)' %log_auc, linewidth = 4)\n",
    "plt.plot(svm_fpr, svm_tpr, label = 'ROC curve SVM (area = %0.5f)' %svm_auc, linewidth = 4)\n",
    "plt.plot(gaussian_fpr, gaussian_tpr, label = 'ROC curve Guassian NB (area = %0.5f)' % gaussian_nb_auc, linewidth = 4)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver Operating Characteristic: M', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrSrz3AAYKe3"
   },
   "source": [
    "### 7. [BONUS] Learning Curve\n",
    "\n",
    "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data.\n",
    "\n",
    "Plot \"learning curves\" for the best models of each. This is a great way see how training/testing size affects the scores. Look at the documentation for how to use this function in sklearn.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:22:19.657638Z",
     "start_time": "2019-05-09T05:22:19.653657Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3Zleg5E-YKe4"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE8SgkpSYKe7"
   },
   "source": [
    "**References**\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/downloads/breast-cancer-wisconsin-data.zip/2)\n",
    "\n",
    "[Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html#learning-curves)\n",
    "\n",
    "[In-Depth: Support Vector Machines](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n",
    "\n",
    "[Understanding Support Vector Machine algorithm from examples (along with code)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)\n",
    "\n",
    "[Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IOD_Lab_5_3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
