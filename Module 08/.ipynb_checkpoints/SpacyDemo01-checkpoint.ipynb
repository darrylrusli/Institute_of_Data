{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Demo01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/spacy/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.2.3-cp38-cp38-win_amd64.whl (11.6 MB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp38-cp38-win_amd64.whl (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from spacy) (4.63.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from spacy) (21.3)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.15-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.7-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp38-cp38-win_amd64.whl (452 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-win_amd64.whl (113 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: murmurhash, cymem, click, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Successfully installed blis-0.7.7 catalogue-2.0.7 click-8.0.4 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.2.3 spacy-legacy-3.0.9 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.15 typer-0.4.0 wasabi-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darry\\anaconda3\\envs\\ds-ai\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "!PIP install spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download english language model\n",
    "# There are 3 models: small, medoum, large\n",
    "# The small model takes around 4 secs to load\n",
    "# The large model takes around 3 mins\n",
    "# Note that Some functions works only in medoium or large models\n",
    "# %time !python -m spacy download en\n",
    "%time !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
      "/Users/ahmedfattah/opt/anaconda3/lib/python3.7/site-packages/en_core_web_lg -->\n",
      "/Users/ahmedfattah/opt/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy link --force en_core_web_lg en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intantiate nlp class for english\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:Such\t tag:PDT\t\tPOS:DET\t\t text:'Such' \tlemma:such\t \n",
      "token:an\t tag:DT\t\tPOS:DET\t\t text:'an' \tlemma:an\t \n",
      "token:analysis\t tag:NN\t\tPOS:NOUN\t\t text:'analysis' \tlemma:analysis\t \n",
      "token:can\t tag:MD\t\tPOS:VERB\t\t text:'can' \tlemma:can\t \n",
      "token:reveal\t tag:VB\t\tPOS:VERB\t\t text:'reveal' \tlemma:reveal\t \n",
      "token:features\t tag:NNS\t\tPOS:NOUN\t\t text:'features' \tlemma:feature\t \n",
      "token:that\t tag:WDT\t\tPOS:DET\t\t text:'that' \tlemma:that\t \n",
      "token:are\t tag:VBP\t\tPOS:AUX\t\t text:'are' \tlemma:be\t \n",
      "token:not\t tag:RB\t\tPOS:PART\t\t text:'not' \tlemma:not\t \n",
      "token:easily\t tag:RB\t\tPOS:ADV\t\t text:'easily' \tlemma:easily\t \n",
      "token:visible\t tag:JJ\t\tPOS:ADJ\t\t text:'visible' \tlemma:visible\t \n",
      "token:from\t tag:IN\t\tPOS:ADP\t\t text:'from' \tlemma:from\t \n",
      "token:the\t tag:DT\t\tPOS:DET\t\t text:'the' \tlemma:the\t \n",
      "token:variation\t tag:NN\t\tPOS:NOUN\t\t text:'variation' \tlemma:variation\t \n",
      "token:in\t tag:IN\t\tPOS:ADP\t\t text:'in' \tlemma:in\t \n",
      "token:the\t tag:DT\t\tPOS:DET\t\t text:'the' \tlemma:the\t \n",
      "token:individual\t tag:JJ\t\tPOS:ADJ\t\t text:'individual' \tlemma:individual\t \n",
      "token:genes\t tag:NNS\t\tPOS:NOUN\t\t text:'genes' \tlemma:gene\t \n",
      "token:and\t tag:CC\t\tPOS:CCONJ\t\t text:'and' \tlemma:and\t \n",
      "token:can\t tag:MD\t\tPOS:VERB\t\t text:'can' \tlemma:can\t \n",
      "token:lead\t tag:VB\t\tPOS:VERB\t\t text:'lead' \tlemma:lead\t \n",
      "token:to\t tag:IN\t\tPOS:ADP\t\t text:'to' \tlemma:to\t \n",
      "token:a\t tag:DT\t\tPOS:DET\t\t text:'a' \tlemma:a\t \n",
      "token:picture\t tag:NN\t\tPOS:NOUN\t\t text:'picture' \tlemma:picture\t \n",
      "token:of\t tag:IN\t\tPOS:ADP\t\t text:'of' \tlemma:of\t \n",
      "token:expression\t tag:NN\t\tPOS:NOUN\t\t text:'expression' \tlemma:expression\t \n",
      "token:that\t tag:WDT\t\tPOS:DET\t\t text:'that' \tlemma:that\t \n",
      "token:is\t tag:VBZ\t\tPOS:AUX\t\t text:'is' \tlemma:be\t \n",
      "token:more\t tag:RBR\t\tPOS:ADV\t\t text:'more' \tlemma:more\t \n",
      "token:biologically\t tag:RB\t\tPOS:ADV\t\t text:'biologically' \tlemma:biologically\t \n",
      "token:transparent\t tag:JJ\t\tPOS:ADJ\t\t text:'transparent' \tlemma:transparent\t \n",
      "token:and\t tag:CC\t\tPOS:CCONJ\t\t text:'and' \tlemma:and\t \n",
      "token:accessible\t tag:JJ\t\tPOS:ADJ\t\t text:'accessible' \tlemma:accessible\t \n",
      "token:to\t tag:IN\t\tPOS:ADP\t\t text:'to' \tlemma:to\t \n",
      "token:interpretation\t tag:NN\t\tPOS:NOUN\t\t text:'interpretation' \tlemma:interpretation\t \n",
      "token:\n",
      "\t tag:_SP\t\tPOS:SPACE\t\t text:'\n",
      "' \tlemma:\n",
      "\t \n"
     ]
    }
   ],
   "source": [
    "# tokenisation\n",
    "# doc = nlp('Drinking a glass of wine is good for your wellbeing!')\n",
    "doc = nlp('''Such an analysis can reveal features that are not easily visible from the variation in the individual genes and can lead to a picture of expression that is more biologically transparent and accessible to interpretation\n",
    "''')\n",
    "for token in doc:\n",
    "    print(f\"token:{token}\\t tag:{token.tag_}\\t\\tPOS:{token.pos_}\\t\\t text:'{token.text}' \\tlemma:{token.lemma_}\\t \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Apple \t\t type:ORG\n",
      "Entity: U.K. \t\t type:GPE\n",
      "Entity: $1 billion \t\t type:MONEY\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "# doc = nlp(\"He was born in Canberra, Australia in 14/1/1974\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text} \\t\\t type:{ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I just bought \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    9 a.m.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " because the stock went up \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    30%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    just 2 days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " according to the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WSJ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display tag alongside the text\n",
    "from spacy import displacy\n",
    " \n",
    "doc = nlp('I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:Wall Street Journal,\t label:NP,\t root:Journal\n",
      "Text:an interesting piece,\t label:NP,\t root:piece\n",
      "Text:crypto currencies,\t label:NP,\t root:currencies\n"
     ]
    }
   ],
   "source": [
    "# noun-phrase chunking\n",
    "doc = nlp(\"Wall Street Journal just published an interesting piece on crypto currencies\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"Text:{chunk.text},\\t label:{chunk.label_},\\t root:{chunk.root.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aee532dffbe24f319114565e3fe53e41-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Wall</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Street</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Journal</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">just</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">published</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">an</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">interesting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">piece</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">crypto</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">currencies</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,47.0 405.0,47.0 405.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-4\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,139.0 L512,127.0 528,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-6\" stroke-width=\"2px\" d=\"M430,137.0 C430,2.0 680.0,2.0 680.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M680.0,139.0 L688.0,127.0 672.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M760.0,139.0 L768.0,127.0 752.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee532dffbe24f319114565e3fe53e41-0-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee532dffbe24f319114565e3fe53e41-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grammer dependency tree parsing and visualisation\n",
    "from spacy import displacy\n",
    " \n",
    "doc = nlp('Wall Street Journal just published an interesting piece on crypto currencies')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-base matcher\n",
    "# import spacy Matcher\n",
    "from spacy.matcher import Matcher\n",
    "# create a matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# define a function to extract full name\n",
    "def extract_full_name(text: str):\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    matcher.add('FULL_NAME', None, pattern)\n",
    "    doc = nlp(text)\n",
    "    names = []\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        names.append(span.text)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full names: ['John Richardson', 'Daniel Zhang', 'Lucy Khan']\n"
     ]
    }
   ],
   "source": [
    "# Find full name in sentence\n",
    "full_names = extract_full_name(\"I met John Richardson almost a year after Daniel Zhang married Lucy Khan\")\n",
    "print(f\"Full names: {full_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token list: \n",
      "['He', 'determined', 'to', 'drop', 'his', 'litigation', 'with', 'the', 'monastry', ',', 'and', 'relinguish', 'his', 'claims', 'to', 'the', 'wood', '-', 'cuting', 'and', '\\n', 'fishery', 'rihgts', 'at', 'once', '.', 'He', 'was', 'the', 'more', 'ready', 'to', 'do', 'this', 'becuase', 'the', 'rights', 'had', 'become', 'much', 'less', 'valuable', ',', 'and', 'he', 'had', '\\n', 'indeed', 'the', 'vaguest', 'idea', 'where', 'the', 'wood', 'and', 'river', 'in', 'question', 'were', '.']\n",
      "\n",
      "Filtered text: \n",
      "['determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood', '-', 'cuting', '\\n', 'fishery', 'rihgts', '.', 'ready', 'becuase', 'rights', 'valuable', ',', '\\n', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "filtered_text =[] \n",
    "nlp_text = nlp(text)\n",
    "token_list = []\n",
    "for token in nlp_text:\n",
    "    token_list.append(token.text)\n",
    "for word in token_list:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    if lexeme.is_stop == False:\n",
    "        filtered_text.append(word)\n",
    "print(f\"Token list: \\n{token_list}\")\n",
    "print(f\"\\nFiltered text: \\n{filtered_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:\tdog, has vector:\tTrue, token.vector_norm, token.is_oov\n",
      "Token:\tcat, has vector:\tTrue, token.vector_norm, token.is_oov\n",
      "Token:\tbanana, has vector:\tTrue, token.vector_norm, token.is_oov\n",
      "Token:\tafskfsd, has vector:\tFalse, token.vector_norm, token.is_oov\n",
      "\n",
      "Token 1: dog\n",
      " Vector:\n",
      "[-4.0176e-01  3.7057e-01  2.1281e-02 -3.4125e-01  4.9538e-02  2.9440e-01\n",
      " -1.7376e-01 -2.7982e-01  6.7622e-02  2.1693e+00 -6.2691e-01  2.9106e-01\n",
      " -6.7270e-01  2.3319e-01 -3.4264e-01  1.8311e-01  5.0226e-01  1.0689e+00\n",
      "  1.4698e-01 -4.5230e-01 -4.1827e-01 -1.5967e-01  2.6748e-01 -4.8867e-01\n",
      "  3.6462e-01 -4.3403e-02 -2.4474e-01 -4.1752e-01  8.9088e-02 -2.5552e-01\n",
      " -5.5695e-01  1.2243e-01 -8.3526e-02  5.5095e-01  3.6410e-01  1.5361e-01\n",
      "  5.5738e-01 -9.0702e-01 -4.9098e-02  3.8580e-01  3.8000e-01  1.4425e-01\n",
      " -2.7221e-01 -3.7016e-01 -1.2904e-01 -1.5085e-01 -3.8076e-01  4.9583e-02\n",
      "  1.2755e-01 -8.2788e-02  1.4339e-01  3.2537e-01  2.7226e-01  4.3632e-01\n",
      " -3.1769e-01  7.9405e-01  2.6529e-01  1.0135e-01 -3.3279e-01  4.3117e-01\n",
      "  1.6687e-01  1.0729e-01  8.9418e-02  2.8635e-01  4.0117e-01 -3.9222e-01\n",
      "  4.5217e-01  1.3521e-01 -2.8878e-01 -2.2819e-02 -3.4975e-01 -2.2996e-01\n",
      "  2.0224e-01 -2.1177e-01  2.7184e-01  9.1703e-02 -2.0610e-01 -6.5758e-01\n",
      "  1.8949e-01 -2.6756e-01  9.2639e-02  4.3316e-01 -4.8868e-01 -3.8309e-01\n",
      " -2.1910e-01 -4.4183e-01  9.8044e-01  6.7423e-01  8.4003e-01 -1.8169e-01\n",
      "  1.7385e-01  4.1848e-01  1.6098e-01 -1.0490e-01 -4.1965e-01 -3.5660e-01\n",
      " -1.6837e-01 -6.3458e-01  3.8422e-01 -3.5043e-01  1.7486e-01  5.3528e-01\n",
      "  2.0143e-01  3.7877e-02  4.7105e-01 -4.4344e-01  1.6840e-01 -1.6685e-01\n",
      " -2.4022e-01 -1.0077e-01  3.0334e-01  4.2730e-01  3.3803e-01 -4.3481e-01\n",
      "  1.1343e-01  6.1958e-02  6.1808e-02 -1.4007e-01  8.2018e-02 -3.9130e-02\n",
      "  5.1442e-02  2.8725e-01  5.8025e-01 -5.7641e-01 -3.4652e-01  1.0132e-01\n",
      "  1.4463e-01  1.1569e-02 -3.3701e-01 -1.7586e-01 -3.5724e-01 -2.1423e-01\n",
      "  1.1429e-02  4.7645e-01 -3.7463e-02 -2.9488e-01 -1.7465e-01  3.0255e-01\n",
      "  6.0317e-01 -6.6790e-02 -2.7050e+00 -7.0308e-01  4.0548e-01  6.2874e-01\n",
      "  6.3080e-01 -5.4513e-01 -9.6191e-03  2.6533e-01  2.3391e-01 -5.1886e-02\n",
      " -6.5759e-03  1.8573e-02 -4.5693e-01 -7.0351e-02 -3.0621e-01 -1.4018e-02\n",
      " -2.0408e-01  3.7100e-01 -3.2354e-01 -8.4646e-01  2.7092e-01 -1.1961e-01\n",
      " -9.5576e-02 -6.0464e-01  4.2409e-02  2.4656e-01  3.8445e-02 -2.5467e-02\n",
      " -9.2908e-02 -2.1356e-01  3.6120e-01  1.9113e-02  6.2741e-02 -1.3083e-01\n",
      " -1.5146e-03  5.8238e-01 -1.8956e-01  7.8105e-01  1.0477e-02  1.0928e+00\n",
      "  1.0140e-01 -3.6248e-01 -1.1962e-01 -3.4462e-01 -5.5704e-01  2.5797e-01\n",
      "  3.3356e-01  3.3194e-01 -3.1298e-01 -7.5547e-01 -7.5290e-01 -9.3072e-02\n",
      " -1.1173e-01 -5.7251e-01  1.6639e-01  6.3579e-01  2.4006e-01 -2.9211e-01\n",
      "  9.0182e-01  1.2425e-01 -5.7751e-01  4.7986e-02 -4.2748e-01  2.4446e-01\n",
      "  4.7232e-02  3.5694e-01  4.4241e-01 -2.3055e-01  6.6037e-01 -7.3983e-03\n",
      " -3.7857e-01  2.2759e-01 -3.7138e-01  3.1055e-01 -7.2105e-02 -2.4490e-01\n",
      " -3.9761e-02  5.3650e-01 -4.1478e-01  1.6563e-01  3.3707e-01  1.0920e-01\n",
      "  3.7219e-01 -5.5727e-01 -7.8060e-01  1.4251e-01 -3.5828e-01  4.1638e-01\n",
      "  2.1446e-01  1.8410e-01 -4.7704e-01 -2.2005e-02 -2.3634e-01 -2.2840e-01\n",
      "  3.4722e-01  2.3667e-01  7.4249e-02 -8.8416e-02  2.8618e-01 -4.6942e-01\n",
      " -4.3914e-01 -2.6474e-01 -3.0690e-01 -1.5260e-01 -8.4870e-02  2.8410e-01\n",
      " -1.8481e-01 -2.2122e-01 -1.1169e-01 -2.5241e-02  4.5968e-02  3.5343e-02\n",
      "  2.2467e-01  5.1556e-01 -6.5137e-04  9.9559e-02 -1.4215e-01  2.0136e-01\n",
      "  2.8334e-01 -2.8772e-01  3.7766e-02 -3.7608e-01 -1.1681e-01 -6.7020e-01\n",
      " -4.6265e-02  3.8784e-01 -3.2295e-02 -5.4291e-02 -4.5384e-01  1.9552e-01\n",
      " -2.9470e-01  8.5009e-01  1.0345e-01  9.7010e-02  1.1339e-01  3.9502e-01\n",
      "  5.9043e-02  2.1978e-01  1.8845e-01 -1.5891e-01 -1.0301e-01  3.3164e-01\n",
      "  6.1477e-02 -2.9848e-01  4.4510e-01  4.7329e-01  2.6312e-01 -1.8495e-01\n",
      "  1.4652e-01 -3.1510e-02  2.2908e-02 -2.5929e-01 -3.0862e-01  1.7545e-03\n",
      " -1.8962e-01  5.4789e-01  3.1194e-01  2.4693e-01  2.9929e-01 -7.4861e-02]\n"
     ]
    }
   ],
   "source": [
    "# word vectors\n",
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "for token in tokens:\n",
    "    print(f\"Token:\\t{token.text}, has vector:\\t{token.has_vector}, token.vector_norm, token.is_oov\")\n",
    "print(f\"\\nToken 1: {tokens[0]}\\n Vector:\\n{tokens[0].vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1:\tdog,\t token 2:dog,\t similarity:1.0\n",
      "Token 1:\tdog,\t token 2:cat,\t similarity:0.5080135464668274\n",
      "Token 1:\tdog,\t token 2:banana,\t similarity:0.3817077875137329\n",
      "Token 1:\tdog,\t token 2:apple,\t similarity:0.24964354932308197\n",
      "Token 1:\tcat,\t token 2:dog,\t similarity:0.5080135464668274\n",
      "Token 1:\tcat,\t token 2:cat,\t similarity:1.0\n",
      "Token 1:\tcat,\t token 2:banana,\t similarity:0.5098239183425903\n",
      "Token 1:\tcat,\t token 2:apple,\t similarity:0.27301254868507385\n",
      "Token 1:\tbanana,\t token 2:dog,\t similarity:0.3817077875137329\n",
      "Token 1:\tbanana,\t token 2:cat,\t similarity:0.5098239183425903\n",
      "Token 1:\tbanana,\t token 2:banana,\t similarity:1.0\n",
      "Token 1:\tbanana,\t token 2:apple,\t similarity:0.4156864285469055\n",
      "Token 1:\tapple,\t token 2:dog,\t similarity:0.24964354932308197\n",
      "Token 1:\tapple,\t token 2:cat,\t similarity:0.27301254868507385\n",
      "Token 1:\tapple,\t token 2:banana,\t similarity:0.4156864285469055\n",
      "Token 1:\tapple,\t token 2:apple,\t similarity:1.0\n"
     ]
    }
   ],
   "source": [
    "# Word similarity\n",
    "tokens = nlp(\"dog cat banana apple\")\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(f\"Token 1:\\t{token1.text},\\t token 2:{token2.text},\\t similarity:{token1.similarity(token2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textBlob in /Users/ahmedfattah/opt/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/ahmedfattah/opt/anaconda3/lib/python3.7/site-packages (from textBlob) (3.4.5)\n",
      "Requirement already satisfied: six in /Users/ahmedfattah/opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textBlob) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analys with textBlob\n",
    "!pip install textBlob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.8, subjectivity=1.0)\n"
     ]
    }
   ],
   "source": [
    "# Detect sentiment of a text\n",
    "# text = \"Textblob is amazingly simple to use. What great fun!\"\n",
    "text=\"I am so happy with my progress in the data science course\"\n",
    "textBlob = TextBlob(text)\n",
    "print(f\"{textBlob.sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
